{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMT87SHmCsJr"
   },
   "source": [
    "# Classificador com corpus de brinquedo\n",
    "\n",
    "Vamos modelizar um conjunto fictício de resenhas de clientes sobre determinado restaurante. Além dos textos, temos à disposição uma etiqueta para cada resenha informando se a opinião do cliente soa positiva ou negativa.\n",
    "\n",
    "A partir das probabilidades calculadas, será possível gerar uma função que avalie novas resenhas, classificando-as como positivas ou negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ErO-M5JaCqHh"
   },
   "outputs": [],
   "source": [
    "# Estas são as resenhas para a modelização:\n",
    "corpus = [('Esse restaurante é um lixo', 'NEG'), ('A comida servida no inferno', 'NEG'),\n",
    "          ('Lugar imundo', 'NEG'), ('Perfeito para o seu cachorro', 'POS'), ('Restaurante ótimo', 'POS')]\n",
    "\n",
    "# Esta é a resenha com a qual vamos testar o classificador. Você pode tentar com outras, também.\n",
    "teste = 'Restaurante horroroso. A comida é lixo em estado coloidal! O outro emprego do garçom é carcereiro de masmorra.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejBYv_I3tHxb"
   },
   "source": [
    "**Pré-processamento:**\n",
    "\n",
    "*   Tokenização\n",
    "*   Limpeza\n",
    "* Filtragem de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BULRgox-tlW9",
    "outputId": "e1904d13-4592-447b-cdce-bb0471d6cebb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/brunorosilva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/brunorosilva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from numpy import prod\n",
    "from math import log\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import tokenize \n",
    "nltk.download('stopwords')\n",
    "stops = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "\n",
    "def tokenizar(str_texto):\n",
    "    return tokenize.word_tokenize(str_texto, language='portuguese')\n",
    "\n",
    "\n",
    "def sem_stops(lst_palavras):\n",
    "    return [p for p in lst_palavras if p not in stops]\n",
    "\n",
    "\n",
    "def limpar(lista):\n",
    "    return [i.lower() for i in lista if i.isalpha()]\n",
    "\n",
    "\n",
    "def pre_processar(str_texto):\n",
    "    return sem_stops(limpar(tokenizar(str_texto)))\n",
    "\n",
    "\n",
    "def achatar(lista):\n",
    "    return list(itertools.chain(*lista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdMNHGery7VC",
    "outputId": "fe0410db-fc6f-4614-ed97-b12fd697b0b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['restaurante', 'lixo'], 'NEG'),\n",
       " (['comida', 'servida', 'inferno'], 'NEG'),\n",
       " (['lugar', 'imundo'], 'NEG'),\n",
       " (['perfeito', 'cachorro'], 'POS'),\n",
       " (['restaurante', 'ótimo'], 'POS')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [(pre_processar(i[0]), i[1]) for i in corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1TiO8C8yAT6"
   },
   "source": [
    "**Separação dos documentos**\n",
    "\n",
    "*   Extração de duas listas separadas contendo documentos etiquetados como \"negativos\" e \"positivos\"\n",
    "*   Extração do vocabulário total do corpus (juntando as palavras das resenhas positivas e das negativas). Atenção! Lembre-se de que o vocabulário são as palavras sem repetição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bNjnbK_zzuuX"
   },
   "outputs": [],
   "source": [
    "negativos = [i[0] for i in corpus if i[1] == 'NEG']\n",
    "positivos = [i[0] for i in corpus if i[1] == 'POS']\n",
    "\n",
    "vocab = set(achatar(negativos)) | set(achatar(positivos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxWx3sBMxe5m"
   },
   "source": [
    "**Contagens**\n",
    "\n",
    "*   *N* documentos negativos\n",
    "*   *N* documentos positivos\n",
    "* *N* total de documentos\n",
    "\n",
    "* *N* itens no vocabulário\n",
    "* Contagens de ocorrências de cada palavra nas resenhas negativas. **Dica:** use a função `Counter()` do módulo `collection`s para isso.\n",
    "* Contagens de ocorrências de cada palavra nas resenhas positivas. \n",
    "* *N* total de palavras \"negativas\"\n",
    "* *N* total de palavras \"positivas\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nXohzJAf0Z0E"
   },
   "outputs": [],
   "source": [
    "# Contagens de documentos (resenhas)\n",
    "n_docs_negativos = len(negativos)\n",
    "n_docs_positivos = len(positivos)\n",
    "n_docs_total = n_docs_negativos + n_docs_positivos\n",
    "\n",
    "# N itens no vocabulário\n",
    "n_vocab = len(vocab)\n",
    "\n",
    "# Contagens de cada palavra (dicionários de ocorrências)\n",
    "tokens_neg = achatar(negativos)\n",
    "cont_neg = Counter(tokens_neg)\n",
    "tokens_pos = achatar(positivos)\n",
    "cont_pos = Counter(tokens_pos)\n",
    "\n",
    "# N total de palavras em cada classe\n",
    "n_tokens_neg = sum(cont_neg.values())\n",
    "n_tokens_pos = sum(cont_pos.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNWj5Y3V4AJw"
   },
   "source": [
    "**Cálculo das probabilidades de classificação**\n",
    "\n",
    "Há duas probabilidades a calcular, uma para cada classe ($c$): a probabilidade de uma resenha qualquer ser negativa e a probabilidade de ela ser falsa.\n",
    "\n",
    "Essa probabilidade é dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "P(c) \\prod\\limits_{i=1}^n P(f_{i} | c)\n",
    "\\end{equation}\n",
    "\n",
    "Onde a probabilidade de cada atributo $f$ é dada pelo número de ocorrências (tokens) desse atributo dividido pelo número de tokens em cada classe.\n",
    "\n",
    "**Dica:** para calcular o produtório de uma lista, use a função `prod` do módulo `numpy`.\n",
    "\n",
    "\n",
    "Vamos suavizar a classificação com o método de Laplace, isto é, somando 1 a cada atributo no numerador e somando também a cardinalidade do vocabulário ao denominador.\n",
    "\n",
    "A probabilidade isolada (anterior) da classe $c$ é dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\tP(c) = \\dfrac{contagem(c)}{N}\n",
    "\\end{equation}\n",
    "\n",
    "Já a probabilidade suavizada de um atributo qualquer pertencer a $c$ é:\n",
    "\n",
    "\\begin{equation}\n",
    "\tP(f_{i} | c) = \\dfrac{contagem(f_{i},c) + 1}{contagem(c) + V}\n",
    " \\end{equation}\n",
    "\n",
    "Por fim, para evitar o underflow aritmético, é sempre uma boa ideia calcular probabilidades encadeadas com logaritmos. A diferença com documentos e vocabulários pequenos não é grande, mas tende a ser quando se trabalha com dados reais.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{c} = \\underset{c \\in \\mathcal{C}}{\\operatorname{argmax}} \\ \\log P(c) + \\sum\\limits_{i=1}^n \\log P(f_{i} | c)\n",
    "\\end{equation}\n",
    "\n",
    "Agora, com base nessas informações, procure classificar a mensagem-teste apresentada acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvCKi9W6yX4F",
    "outputId": "7572d1e5-2137-4ee1-f112-3c3071684e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurante horroroso. A comida é lixo em estado coloidal! O outro emprego do garçom é carcereiro de masmorra.\n",
      "-6.931024114254803 -8.140315540159985\n",
      "O cliente não gostou do restaurante.\n"
     ]
    }
   ],
   "source": [
    "tokens_teste = pre_processar(teste)\n",
    "tokens_teste = [i for i in tokens_teste if i in vocab]\n",
    "\n",
    "# Com logs\n",
    "prob_neg = log(n_docs_negativos / n_docs_total) + sum([log((cont_neg[i] + 1) / (n_tokens_neg + n_vocab)) for i in tokens_teste])\n",
    "prob_pos = log(n_docs_positivos / n_docs_total) + sum([log((cont_pos[i] + 1) / (n_tokens_pos + n_vocab)) for i in tokens_teste])\n",
    "\n",
    "print(teste)\n",
    "print(prob_neg, prob_pos)\n",
    "if prob_neg > prob_pos:\n",
    "    print('O cliente não gostou do restaurante.')\n",
    "else:\n",
    "    print('O cliente gostou do restaurante.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht6ps2uGC1u7"
   },
   "source": [
    "---\n",
    "\n",
    "# **Tarefa:** Detecção de spam com corpus de dados reais\n",
    "\n",
    "Nessa tarefa, você vai trabalhar com parte do corpus de mensagens de e-mail da Enron.\n",
    "\n",
    "As mensagens estão em arquivos de texto curtos em inglês (principalmente, mas não só) e têm anotações manuais no título e na primeira linha de texto com sua etiqueta como \"spam\" (1) ou \"ham\" (0). \n",
    "\n",
    "Aqui está uma mensagem de exemplo:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "0\n",
    "\n",
    "Subject: meter 1517 - jan 1999\n",
    "george ,\n",
    "i need the following done :\n",
    "jan 13\n",
    "zero out 012 - 27049 - 02 - 001 receipt package id 2666\n",
    "allocate flow of 149 to 012 - 64610 - 02 - 055 deliv package id 392\n",
    "jan 26\n",
    "zero out 012 - 27049 - 02 - 001 receipt package id 3011\n",
    "zero out 012 - 64610 - 02 - 055 deliv package id 392\n",
    "these were buybacks that were incorrectly nominated to transport contracts\n",
    "( ect 201 receipt )\n",
    "let me know when this is done\n",
    "hc\n",
    "\n",
    "---\n",
    "\n",
    "Observe o 0 na primeira linha. Ele indica que a mensagem foi etiquetada como *ham*.\n",
    "\n",
    "Você deve:\n",
    "\n",
    "\n",
    "\n",
    "1.   Abrir cada arquivo de texto.\n",
    "2.   Pré-processar os dados, implementando os seguintes procedimentos:\n",
    "\n",
    "*   Tokenização\n",
    "* Eliminação de stop words\n",
    "*   Limpeza e homogeneização dos tokens\n",
    "* Stemização\n",
    "\n",
    "Use o NLTK para gerar a lista de stop words em inglês e para implementar um stemizador também em inglês:\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "import nltk\n",
    "stops = nltk.corpus.stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stemizar(lista):\n",
    "    return [stemmer.stem(i) for i in lista]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "3. Dividir o corpus pré-processado em treinamento (80%) e teste (20%).\n",
    "\n",
    "4. Usando o corpus de treinamento, realizar as contagens do vocabulário, das classes (*spam* ou *ham*) e dos atributos (cada token corresponde a um atributo).\n",
    "\n",
    "5. Calcular as probabilidades relacionadas às contagens.\n",
    "\n",
    "6. Implementar uma função bayes() que receba uma mensagem e devolva a probabilidade de ela ser classificada como *spam* e como *ham*:\n",
    "\n",
    "`return prob_spam, prob_ham`\n",
    "\n",
    "7. Nessa função, não deixe de incluir:\n",
    "\n",
    "* Uma condicional para testar se as palavras a classificar fazem parte do vocabulário de treinamento. As que não fazem devem ser simplesmente ignoradas (ficar de fora do cálculo).\n",
    "\n",
    "* A suavização de Laplace.\n",
    "\n",
    "7. Classificar todo o corpus de teste passando cada mensagem pela função bayes().\n",
    "\n",
    "8. Avaliar a performance do classificador: para cada mensagem, comparar a classificação com as etiquetas de *spam* ou *ham* e gerar uma lista com os resultados dessa avaliação em termos de Verdadeiro Positivo (VP), Verdadeiro Negativo (VN), Falso Positivo (FP) e Falso Negativo (FN).\n",
    "\n",
    "9. Com base nessa lista, calcular:\n",
    "\n",
    "* precisao = vp / (vp + fp)\n",
    "* cobertura = vp / (vp + fn)\n",
    "* acuracia = (vp + vn) / (vp + vn + fp + fn)\n",
    "* Medida_F = 2 * (precisao * cobertura) / (precisao + cobertura)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classificador_Bayesiano_Ingênuo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
