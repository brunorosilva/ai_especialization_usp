{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercício: Detecção de Spam com Rede Neural.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7mDaLZuzkHI"
      },
      "source": [
        "# Preparação do corpus e pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBNhq9XZu5px"
      },
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "arquivo = files.upload()\n",
        "!unzip 'Enron.zip' -d 'enron'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxapdkZO5tgl"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stops = nltk.corpus.stopwords.words('english')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "def tokenizar(str_texto):\n",
        "    return word_tokenize(str_texto)\n",
        "\n",
        "def limpar(lista):\n",
        "    return [i.lower() for i in lista if i.isalpha()]\n",
        "\n",
        "def sem_stops(lista):\n",
        "    return [i for i in lista if i not in stops]\n",
        "\n",
        "def stemizar(lista):\n",
        "    return [stemmer.stem(i) for i in lista]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0yd20Yz52pM"
      },
      "source": [
        "arqs = glob.glob('enron/*.txt')\n",
        "mensagens = list()\n",
        "etiquetas = list()\n",
        "for arq in arqs:\n",
        "    arquivo = open(arq, 'r')\n",
        "    classe = int(arquivo.readline()[0])  # Pega só o número e deixa de fora o \\n\n",
        "    \n",
        "    texto = arquivo.read()\n",
        "    texto = stemizar(sem_stops(limpar(tokenizar(texto))))\n",
        "    mensagens.append(texto)\n",
        "    etiquetas.append(classe)\n",
        "    arquivo.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtjYDLXt_Y64",
        "outputId": "13afaf71-d690-41df-bf38-db76ab024181"
      },
      "source": [
        "# Conferindo...\n",
        "etiquetas[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUjcxcE2HUT"
      },
      "source": [
        "# Codificação (encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOUr__4Xy1sN",
        "outputId": "687a03f1-59cd-4374-cd84-1eb9f09f4fb8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab = set([p for sent in mensagens for p in sent])\n",
        "\n",
        "# Cria um dicionário {palavra: índice}\n",
        "indices_de_palavras = {palavra: e+1 for e, palavra in enumerate(vocab)}  # e+1 para que o primeiro índice não seja 0, que é um pad\n",
        "\n",
        "# Gera um vetor de índices de palavras para cada mensagem\n",
        "vetores_msg = np.array([[indices_de_palavras[p] for p in d] for d in mensagens], dtype=object)\n",
        "vetores_msg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([10122, 11196, 26047, 6504, 19166, 15434, 27702, 36643, 11196, 32418, 886, 19166, 10558, 32418, 886, 8610, 493, 19019, 17879]),\n",
              "       list([10122, 7339, 34511, 17524, 1053, 9760, 8338, 33655, 5777, 10083, 26517, 24228, 10960, 7339, 2775, 23854, 18133, 1710, 22551, 15344, 26719, 13696, 15344, 13936, 19499, 7339, 23854, 24228, 10960, 31518, 12955, 1545]),\n",
              "       list([10122, 22498, 37772, 9076, 22436, 5146, 18412, 22056, 4783, 6439, 19883, 9953, 11419, 3791, 15013, 28293, 18412, 22056, 4783, 6439, 19883, 10122, 22498, 37772, 9076, 22436, 36968, 17867, 25383, 8238, 35722, 24147, 9076, 22498, 37772, 22498, 36279, 2129, 2971, 35722, 22436, 35476, 6769, 32358, 3763, 22436, 15434, 1402, 19126, 1545, 17961, 5146, 9953, 11419, 30330, 3791, 20864, 29732, 1537, 16248, 6799, 3763, 36883, 4740, 11715, 30599, 22973, 4906, 17867, 20864, 6769, 37892, 25299, 7725, 2003, 17867, 26515, 16832, 6138, 31672, 15434, 1402, 19126, 22436, 1545, 3560, 5146, 1537, 16248, 6439, 19883, 15554, 26432, 12881, 7676, 15554, 1537, 16248, 3791, 7676, 15013, 10122, 22498, 37772, 9076, 14708, 1537, 16248, 15385, 34773, 8835, 33568, 11715, 3791, 30330, 31466, 15841, 32662, 23977, 10122, 9076, 17867, 13596, 14731, 32092, 14708, 16248, 1545, 12392, 31518, 36968, 9076, 37142, 17867, 13596, 3791, 17976, 37450, 13358, 30412, 37772, 30176, 20802, 3791, 26866, 20864, 34264, 6153, 1228, 1563, 36231, 36883, 6769, 32358, 10389, 17867, 20864, 26515, 2003, 17867, 5059, 13958, 22968, 27498, 9279, 7725, 16832, 32358, 7725, 31777, 35091, 16832, 31672, 5777, 6138, 27208, 7172, 1378, 31423, 36728, 22282, 5059, 13958, 27208, 34192, 3834, 17734, 31386, 13657, 15344, 26120, 36787, 27191, 36903, 13273, 16832, 10889, 16714, 36903, 29861, 10960, 26735, 7725, 21921, 11466, 11282, 14407, 27487, 15980, 31777, 35091, 18074, 5059, 25299, 37270, 18094, 17272, 17867, 3791, 26735, 12706, 31423, 5146, 9076, 33130, 9781, 33785, 29734, 12654, 7912, 32887, 37270, 22579, 13596, 37142, 35840, 35562, 35209, 4883, 8338, 35840, 25383, 3964, 9076, 7634, 13631, 1545, 31518, 4906, 5146, 28834, 7302, 11608, 21596, 13441, 15434, 18769, 32796, 20321, 10025, 26432, 12881, 7676, 21311, 22498, 37772, 24147, 9076, 20971, 9076, 20971]),\n",
              "       ...,\n",
              "       list([10122, 13169, 6209, 17524, 14952, 7339, 4931, 7339, 17222, 26719, 33564, 20321, 12367, 26735, 18074, 17734, 20094, 20321, 26719, 27393, 21984, 1888, 25025, 1710, 9279, 7339, 19706, 31978, 25476, 15554, 25510, 26065, 37085, 3791, 3791, 35718, 9418, 34330, 6439, 19883, 19883, 36513, 29416, 6439, 32720, 32720, 15013, 10122, 13169, 6209, 23854, 32418, 1053, 25449, 13169, 6209, 17524, 14952, 7339, 10960, 35718, 8833, 23854, 1710, 9279, 37185, 6547, 17734, 10960, 15074, 21875, 18067, 23531, 17524, 14952, 7339, 1710, 9679, 25510, 26065, 3791, 15554, 19706, 31978, 25476, 6439, 19883, 19883, 15013, 10122, 13169, 6209, 19706, 35787, 13169, 6209, 27393, 23933, 8298, 12007, 13973, 13169, 6209, 28312, 32418, 12007, 7339, 7912, 8277, 35075, 1545, 31423, 25510, 5146, 25510, 26065, 37085, 3791, 15554, 5084, 37171, 25510, 26065, 37085, 3791, 3791, 15013, 10122, 13169, 6209, 5146, 5084, 37171, 30330, 3791, 35718, 9418, 34330, 19883, 19706, 31978, 25476, 6439, 19883, 19883, 15013, 5084, 37171, 30330, 3791, 3791, 10122, 13169, 6209, 18355, 16832, 1053, 22324, 9279, 7339, 1228, 7328, 16832, 1053, 18339, 9279, 1402, 19126, 21984, 15705, 18213, 12098, 15554, 35718, 9418, 34330, 6439, 19883, 19883, 15013, 5084, 37171, 30330, 3791, 3791, 10122, 13169, 6209, 26719, 5279, 22324, 5668, 17612, 17085, 11995, 26300, 25967, 31207, 26719, 5084, 37171, 14291]),\n",
              "       list([10122, 17941, 32887, 20802, 2590, 11466, 32887, 20973, 37237, 27191, 8926, 21729, 32887, 20973, 20743, 32887, 5329, 5329, 4448, 16787, 24819, 1545, 26719, 19706, 31978, 25476, 24819, 27241, 6439, 19883, 19883, 3560, 35303, 6439, 19883, 19883, 10086, 1906, 6439, 19883, 19883, 4500, 32154, 6439, 19883, 19883, 261, 30619, 30330, 3791, 3791, 36882, 31091, 30330, 3791, 3791, 26908, 20979, 6439, 19883, 19883, 261, 19082, 6439, 19883, 19883, 15013, 10122, 17941, 32887, 20802, 15434, 22778, 5146, 19706, 31978, 25476, 6439, 19883, 18190, 14294, 3791, 19706, 31978, 25476, 6439, 19883, 19883, 32925, 7802, 30330, 3791, 3791, 27626, 6710, 6439, 19883, 19883, 15013, 10122, 17941, 32887, 20802, 5131, 10981, 1378, 23186, 8543, 36082, 1919, 34029, 31672, 37237, 37237, 35971, 35971, 2817, 26162, 6543, 23977, 18865, 6769, 7042, 18580, 37237, 35971, 18143, 11775, 582, 6740, 17173, 12550, 31777, 28856, 5555, 23186, 33781, 37237, 35971, 18194, 9418, 32662, 23977, 4931, 17173, 29367, 6658, 19794, 5777, 37369, 20053, 6769, 22053, 30894, 30639, 31396, 24678, 25842, 37237, 35971, 8779, 12165, 15841, 36168, 3426]),\n",
              "       list([10122, 30044, 27646, 18769, 20725, 18769, 18074, 15909, 19375, 1110, 7580, 26162, 31775, 34967, 25123, 25939, 13249, 10960, 18255, 3949, 29868, 36022, 34707, 2763, 2332, 1724, 28701, 9386, 8911, 22743, 30672, 37237, 27695, 10025, 18631, 7580, 22732, 7676, 15434, 9770, 8203, 3190, 16161, 9470, 4069, 4931, 21371, 9770, 22902, 19267, 15697, 24498, 27668, 17139, 31518, 26498, 5047])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ngFwAe0HXT",
        "outputId": "d768c046-a4ff-4997-dee8-4b0c490dbba6"
      },
      "source": [
        "# Conferindo...\n",
        "print(len(vocab))\n",
        "indices_de_palavras['viagra']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbOVthwK0Gxp"
      },
      "source": [
        "# Sua vez: conversão para vetores binários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoAEzPTu0jlP"
      },
      "source": [
        "def binarizar(matriz_int, dim= #????):\n",
        "    binarizado = np.zeros((len(matriz_int), dim))\n",
        "\n",
        "    for e, vetor in enumerate(matriz_int):\n",
        "        binarizado[e, vetor] = 1.\n",
        "\n",
        "    return binarizado\n",
        "\n",
        "# Conversão em binários dos testos das resenhas (variável X)\n",
        "vetores_msg_bin = #???????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFmUxDIJ-T-q"
      },
      "source": [
        "# Conferindo...\n",
        "print(vetores_msg_bin.shape)\n",
        "vetores_msg_bin[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHdmR7APLPXY"
      },
      "source": [
        "# Binarização das etiquetas de classificação. Variável Y.\n",
        "\n",
        "etiquetas_bin = #???????????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7A3w1sFvMuR"
      },
      "source": [
        "# Conferindo...\n",
        "etiquetas_bin[:10] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HNgJYj01UuN"
      },
      "source": [
        "# Sua vez: partição dos dados em treinamento / teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgncg97kyyXs"
      },
      "source": [
        "# Partição treinamento / teste\n",
        "treino_x = vetores_msg_bin[:round(len(mensagens) * 0.8)]\n",
        "teste_x = vetores_msg_bin[#???????]\n",
        "\n",
        "treino_y = etiquetas_bin[#???????]\n",
        "teste_y = etiquetas_bin[len(treino_y) + 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Q00gDWgDiM"
      },
      "source": [
        "# Criação do modelo de rede"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhB-j-uvN5XJ"
      },
      "source": [
        "Partição dos dados de treinamento em (1) validação e (2) treinamento parcial, tanto X (resenhas) quanto Y (etiquetas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWaIiN3MN9D4"
      },
      "source": [
        "valid_x = treino_x[:2000]\n",
        "treino_x_parcial = treino_x[2000:]\n",
        "valid_y = treino_y[:2000] \n",
        "treino_y_parcial = treino_y[2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znTxIhdH1oOy"
      },
      "source": [
        "# Sua vez \n",
        "\n",
        "Determine os parâmetros faltantes na arquitetura do modelo: forma da camada de entrada e tamanho da camada de saída."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMSafk6egHEe"
      },
      "source": [
        "from keras import models \n",
        "from keras import layers\n",
        "\n",
        "modelo = models.Sequential() \n",
        "modelo.add(layers.Dense(16, activation='relu', input_shape=#???????))\n",
        "modelo.add(layers.Dense(16, activation='relu'))\n",
        "modelo.add(layers.Dense(#???????, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbghZxhVGlty"
      },
      "source": [
        "# Sua vez\n",
        "\n",
        "Preencha os parâmetros para a compilação do modelo de acordo com a informação do comentário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UVySOvGGoyx"
      },
      "source": [
        "# A função de perda escolhida é a entropia cruzada, boa para classificação probabilística,\n",
        "# e binária, pois temos duas classes possíveis para as etiquetas das resenhas (pos. e neg.)\n",
        "# O otimizador é o Adam, sempre uma boa escolha para PLN.\n",
        "# O desempenho será avaliado pela acurácia (\"acc\").\n",
        "\n",
        "modelo.compile(optimizer=#???????, \n",
        "              loss=#???????, \n",
        "              metrics=#???????)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hr5wRG_OONW"
      },
      "source": [
        "Treinamento do modelo compilado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HkB-MzFOQAi"
      },
      "source": [
        "historia = modelo.fit(treino_x_parcial, \n",
        "                    treino_y_parcial, \n",
        "                    epochs=30, \n",
        "                    batch_size=512, \n",
        "                    validation_data=(valid_x, valid_y), \n",
        "                    verbose=0  # já que será gerado um gráfico, não é tão importante ver os números do aprendizado\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkqandbvPkuc"
      },
      "source": [
        "Exibição da evolução da perda no treinamento e na validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVBsnEOiPlxp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dic_historia = historia.history  # dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
        "perda = dic_historia['loss'] \n",
        "perda_valid = dic_historia['val_loss']\n",
        "\n",
        "acuracia = dic_historia['acc']\n",
        "epocas = range(1, len(acuracia) + 1)\n",
        "\n",
        "plt.plot(epocas, perda, 'bo', label='Perda no treinamento')  # “bo” = pontilhado azul\n",
        "plt.plot(epocas, perda_valid, 'b', label='Perda na validação')  # “b” = linha contínua azul\n",
        "plt.title('Perda no Treinamento e na Validação') \n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-uyE_H8QbRi"
      },
      "source": [
        "Exibição da evolução da acurácia no teste e na validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrmo0Ce-Qd0J"
      },
      "source": [
        "plt.clf()  # Limpa a figura\n",
        "\n",
        "acuracia_treino = dic_historia['acc'] \n",
        "acuracia_valid = dic_historia['val_acc']\n",
        "\n",
        "plt.plot(epocas, acuracia_treino, 'bo', label='Acurácia no Treinamento') \n",
        "plt.plot(epocas, acuracia_valid, 'b', label='Acurácia na Validação')\n",
        "plt.title('Acurácia no Treinamento e na Validação') \n",
        "plt.xlabel('Épocas') \n",
        "plt.ylabel('Acurácia') \n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XZ0phFS58Of"
      },
      "source": [
        "# Treinamento com `EarlyStopping`\n",
        "\n",
        "O modelo será treinado novamente com um número grande de épocas, em busca de obter seu melhor desempenho e parar quando encontrá-lo \"automaticamente\", isto é, quando parar de ter melhoria no aprendizado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PddHnqC58Oj"
      },
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "aprendeu_parou = callbacks.EarlyStopping(\n",
        "    min_delta=0.001,  # aprendizado mínimo (resultados menores não contarão como aprendizado)\n",
        "    patience=10,  # por quantas épocas insistir?\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "historia = modelo.fit(treino_x_parcial, \n",
        "                    treino_y_parcial, \n",
        "                    epochs=300, \n",
        "                    batch_size=512, \n",
        "                    validation_data=(valid_x, valid_y),\n",
        "                    callbacks=[aprendeu_parou])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxd2Lkg4CTai"
      },
      "source": [
        "# Sua vez\n",
        "\n",
        "Preencha os parâmetros da função de avaliação. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KRFEju82uQw"
      },
      "source": [
        "avaliacao = modelo.evaluate(#???????, #???????)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnHS4_o03B6G"
      },
      "source": [
        "print('Acurácia na avaliação: ', avaliacao[1], '\\nPerda: ', avaliacao[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eF-LB6h34WB"
      },
      "source": [
        "# Playground!\n",
        "\n",
        "Experimente mudar a arquitetura da rede (tamanho e profundidade de camadas) para ver se são produzidas diferenças nos resultados.\n",
        "\n",
        "E que tal mudar:\n",
        "\n",
        "* A função de perda para `mse` (erro quadrático médio)\n",
        "* A função de ativação para `tanh` (tangente hiperbólica) ao invés de `relu`\n",
        "\n",
        "Use `EarlyStopping` para limitar o número de épocas de aprendizado."
      ]
    }
  ]
}