{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/brunorosilva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, tokenize\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "stop = nltk.corpus.stopwords.words('portuguese')\n",
    "from IPython.display import display, HTML\n",
    "from nltk.lm import MLE\n",
    "nltk.download('punkt')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('DomCasmurro.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.preprocess_done = False\n",
    "        self.stop = nltk.corpus.stopwords.words('portuguese')\n",
    "        self.lst_sents = []\n",
    "        \n",
    "\n",
    "    def _tokenizar(self, s):\n",
    "        return tokenize.word_tokenize(s, language='portuguese')\n",
    "\n",
    "    def _limpar(self, lista):\n",
    "        return [i.lower() for i in lista if i.isalpha()]\n",
    "    \n",
    "    def _achatar(self, lista):\n",
    "        return [i for sublista in lista for i in sublista]\n",
    "    \n",
    "    def _remover_pontuacao(self):\n",
    "        self.pontos = ['...', ':', ';', '!', '?']\n",
    "        for i in self.pontos:\n",
    "            self.corpus = self.corpus.replace(i, '.')\n",
    "        \n",
    "        \n",
    "    def _remover_barra_n(self):\n",
    "        self.corpus_nl_removed = \"\"\n",
    "        for line in self.corpus:\n",
    "            line_nl_removed = line.replace(\"\\n\", \" \")      #removes newlines\n",
    "            self.corpus_nl_removed += line_nl_removed\n",
    "            \n",
    "    def _remover_pontuacao_e_barra_n(self):\n",
    "        self.corpus_limpo = \"\".join([char for char in self.corpus_nl_removed if char not in (self.pontos + ['\\n'])])\n",
    "        \n",
    "    def _estatisticas_corpus(self):\n",
    "        self.sents = sent_tokenize(self.corpus_limpo)\n",
    "        self.words = word_tokenize(self.corpus_limpo)\n",
    "        stats_df = pd.DataFrame({\n",
    "            \"Sentências\":[len(self.sents)],\n",
    "            \"Palavras\":[len(self.words)],\n",
    "            \"Média de palavras por sentença\":[round(len(self.words)/len(self.sents))],\n",
    "            \"Quantidade de palavras únicas\":[len(set(self.words))],\n",
    "        }, index=[\"Estatísticas\"]).transpose()\n",
    "        \n",
    "        display(stats_df)\n",
    "        \n",
    "        \n",
    "    def _criar_lst_sents(self):        \n",
    "        for sentence in self.sents:\n",
    "            if len(sentence) > 0:\n",
    "                self.lst_sents.append(self._limpar(self._tokenizar(sentence)))\n",
    "        for i in range(len(self.lst_sents)):\n",
    "            self.lst_sents[i] = [\"<s>\"] + self.lst_sents[i] + [\"</s>\"]\n",
    "    \n",
    "    def _remover_primeiros(self, n=10):\n",
    "        self.lst_sents = self.lst_sents[10:]\n",
    "    \n",
    "    def preprocess(self):\n",
    "        \n",
    "        if self.preprocess_done == True:\n",
    "            print(\"O preprocessamento já foi feito, você pode criar os modelos diretamente\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Começando o preprocessamento\")\n",
    "            \n",
    "            self._remover_pontuacao()\n",
    "            print(\"Pontuação Removida\")\n",
    "            self._remover_barra_n()\n",
    "            print(\"Quebras de linhas removidas\")\n",
    "            self._remover_pontuacao_e_barra_n()\n",
    "            print(\"Criação do corpus limpo\")\n",
    "            self._estatisticas_corpus()\n",
    "            print(\"Estatísticas do corpus\")\n",
    "            self._criar_lst_sents()\n",
    "            print(\"Criando lst sents\")\n",
    "            self._remover_primeiros()\n",
    "            print(\"Removendo as 10 primeiras linhas (não fazem parte da obra)\")\n",
    "            \n",
    "        self.preprocess_done = True\n",
    "        \n",
    "    def criar_ngrams(self, n_list=[1, 2, 3]):\n",
    "        self.ngrams = {}\n",
    "        \n",
    "        for n in n_list:\n",
    "            self.ngrams[str(n)+\"gram\"] = []\n",
    "            \n",
    "            for s in self.lst_sents:\n",
    "                if s == \".\" and n==1:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.ngrams[str(n)+\"gram\"].append(list(ngrams(s, n)))\n",
    "                    \n",
    "    def predict_text(self, limit=40, seed=42):\n",
    "        self.predicts = {}\n",
    "        for ngram in self.ngrams:\n",
    "            \n",
    "            pred = \"<s> \"\n",
    "            model = MLE(int(ngram[0]))\n",
    "\n",
    "            model.fit(self.ngrams[ngram], vocabulary_text=list(set(self.words))+[\"<s>\", \"</s>\", \"\\n\"])\n",
    "            model.fit(self.ngrams[\"1gram\"])\n",
    "            \n",
    "            for p in model.generate(limit, text_seed=[\"<s>\"], random_seed=seed):\n",
    "                pred = pred+\" \"+p\n",
    "                \n",
    "                if p == \"</s>\":\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            self.predicts[ngram]=pred\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciando um objeto Modelo e criando modelos para ngramas 1, 2 e 3 (padrão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Começando o preprocessamento\n",
      "Pontuação Removida\n",
      "Quebras de linhas removidas\n",
      "Criação do corpus limpo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estatísticas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentências</th>\n",
       "      <td>5760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palavras</th>\n",
       "      <td>83048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Média de palavras por sentença</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantidade de palavras únicas</th>\n",
       "      <td>11196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Estatísticas\n",
       "Sentências                              5760\n",
       "Palavras                               83048\n",
       "Média de palavras por sentença            14\n",
       "Quantidade de palavras únicas          11196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas do corpus\n",
      "Criando lst sents\n",
      "Removendo as 10 primeiras linhas (não fazem parte da obra)\n"
     ]
    }
   ],
   "source": [
    "m = model(corpus)\n",
    "m.preprocess()\n",
    "m.criar_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict_text(seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1gram': '<s>  minha pae protecção um padecem tinha </s>',\n",
       " '2gram': '<s>  não se pintou a principio suppuz que lhe tirasse da terceira </s>',\n",
       " '3gram': '<s>  minha mãe que tinha os seus </s>'}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
