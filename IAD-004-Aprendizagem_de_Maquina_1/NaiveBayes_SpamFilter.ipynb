{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes_SpamFilter.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunorosilva/ai_especialization_usp/blob/master/IAD-004-Aprendizagem_de_Maquina_1/NaiveBayes_SpamFilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P08tnlVFj4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmhJvCSEW6H_",
        "colab_type": "text"
      },
      "source": [
        "# Construindo um Filtro de SPAM com um classificador *Naive Bayes*\n",
        "\n",
        "O problema de filtragem de e-mails não-solicitados (SPAM) é um clássico do processamento de texto.\n",
        "\n",
        "## Base de dados\n",
        "\n",
        "A base [Enron-Spam](http://www2.aueb.gr/users/ion/data/enron-spam/) contém um conjunto de e-mails em inglês pré-rotulados como mensagens legítimas (\"Ham\") e indesejáveis (\"Spam\").\n",
        "\n",
        "A célula abaixo recupera a base e descompacta-a."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdIR7ga-ZqQk",
        "colab_type": "text"
      },
      "source": [
        "## Base de dados\n",
        "\n",
        "A base [Enron-Spam](http://www2.aueb.gr/users/ion/data/enron-spam/) contém um conjunto de e-mails em inglês pré-rotulados como mensagens legítimas (\"Ham\") e indesejáveis (\"Spam\").\n",
        "\n",
        "A célula abaixo recupera a base e descompacta-a."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2NAToQpxgU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5b0b81c5-9112-436e-8a70-8e4d00c40b7f"
      },
      "source": [
        "!wget -O lingspam_public.tar.gz http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
        "!tar xzf lingspam_public.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-21 22:41:47--  http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
            "Resolving www.aueb.gr (www.aueb.gr)... 195.251.255.156\n",
            "Connecting to www.aueb.gr (www.aueb.gr)|195.251.255.156|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz [following]\n",
            "--2020-07-21 22:41:48--  http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
            "Resolving www2.aueb.gr (www2.aueb.gr)... 195.251.255.138\n",
            "Connecting to www2.aueb.gr (www2.aueb.gr)|195.251.255.138|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11564714 (11M) [application/x-gzip]\n",
            "Saving to: ‘lingspam_public.tar.gz’\n",
            "\n",
            "lingspam_public.tar 100%[===================>]  11.03M  1.96MB/s    in 8.2s    \n",
            "\n",
            "2020-07-21 22:41:57 (1.35 MB/s) - ‘lingspam_public.tar.gz’ saved [11564714/11564714]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTYIDFmuYqMi",
        "colab_type": "text"
      },
      "source": [
        "A base tem os subdiretórios ```bare```, ```lemm```, ```lemm_stop``` e ```stop```.\n",
        "Vamos usar neste exercício o subdiretório ```lemm_stop``` que pré-processa as mensagens de forma a remover palavras excessivamente comuns e sub-variedades  gramaticais (e.g.: plural).\n",
        "\n",
        "As mensagens estão sub-divididas de forma aleatória em 10 sub-diretórios.\n",
        "\n",
        "Mensagens indesejadas têm o seu nome iniciado por ```spm```.\n",
        "\n",
        "O código abaixo recebe uma lista de diretórios e retorna duas listas: A primeira com os caminhos de todos os arquivos nestes diretórios.\n",
        "A segunda com um vetor de booleandos indicando se cada arquivo é uma mensagem legítima ou \"Spam\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEFNCDqNPvYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processa_diretorios(diretorios):\n",
        "  rotulos = []\n",
        "  arquivos = []\n",
        "  for d in diretorios:\n",
        "    for a in os.listdir(d):\n",
        "      arquivos.append(os.path.join(d, a))\n",
        "      rotulos.append(a.startswith('spm'))\n",
        "  return arquivos, rotulos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2hql_2_a0EM",
        "colab_type": "text"
      },
      "source": [
        "Exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baTG73k7a1r7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "20bae801-2862-4269-ea83-04800ea3a6cd"
      },
      "source": [
        "arqs, rt = processa_diretorios(['lingspam_public/lemm_stop/part1'])\n",
        "pd.DataFrame({'arquivo': arqs, 'SPAM': rt}).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arquivo</th>\n",
              "      <th>SPAM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lingspam_public/lemm_stop/part1/5-1285msg2.txt</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lingspam_public/lemm_stop/part1/5-1264msg5.txt</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lingspam_public/lemm_stop/part1/3-404msg1.txt</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lingspam_public/lemm_stop/part1/spmsga105.txt</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lingspam_public/lemm_stop/part1/5-1240msg1.txt</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          arquivo   SPAM\n",
              "0  lingspam_public/lemm_stop/part1/5-1285msg2.txt  False\n",
              "1  lingspam_public/lemm_stop/part1/5-1264msg5.txt  False\n",
              "2   lingspam_public/lemm_stop/part1/3-404msg1.txt  False\n",
              "3   lingspam_public/lemm_stop/part1/spmsga105.txt   True\n",
              "4  lingspam_public/lemm_stop/part1/5-1240msg1.txt  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orb1sc1UZwct",
        "colab_type": "text"
      },
      "source": [
        "## Dicionário de palavras\n",
        "\n",
        "Vamos construir um classificador do tipo \"bag of words\", que considera apenas a *presença* de uma palavra em um texto, ignorando a sua posição.\n",
        "Neste, a cada entrada será atribuído um vetor que contém na sua $i$-gésima posição a quantidade de vezes que a palavra de índice $i$ aparece.\n",
        "\n",
        "Para tanto, em primeiro lugar precisamos construir um dicionário que atribui índices a palavras.\n",
        "Podemos usar o próprio corpo das mensagens para construir este dicionário.\n",
        "O código abaixo recebe uma lista de arquivos e um inteiro e retorna dois objetos, um dicionário de palavras->índices e uma lista com palavras.\n",
        "O inteiro diz a quantidade de palavras a ser extraída (são recuperadas as mais comuns)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "625d2tKSFtY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gera_dicionario(arquivos, corte):\n",
        "    tudo = []       \n",
        "    for arquivo in arquivos:    \n",
        "        with open(arquivo) as a:\n",
        "            for i, l in enumerate(a):\n",
        "                if i == 2:  # Mensagem comça a partir da 3a linha\n",
        "                    palavras = l.split()\n",
        "                    tudo += palavras\n",
        "    dicionario = Counter(tudo)\n",
        "    # Limpa o dicionário: retira tudo que não for texto ou palavras com menos que 2 caracteres\n",
        "    for palavra in list(dicionario.keys()): \n",
        "      if (not palavra.isalpha()) or len(palavra) < 2: \n",
        "          del dicionario[palavra]\n",
        "    # Retém apenas as mais comuns\n",
        "    dicionario = dicionario.most_common(corte)\n",
        "    palavra_id = {}\n",
        "    id_palavra = []\n",
        "    for i, p in enumerate(dicionario):\n",
        "      palavra_id[p[0]]=i\n",
        "      id_palavra.append(p[0])\n",
        "    return palavra_id, id_palavra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib3YBvhOb8Xz",
        "colab_type": "text"
      },
      "source": [
        "Vamos gerar um dicionário usando os arquivos em ```part1```, ```part2``` e ```part3```.\n",
        "Serão retidas as 3000 palavras mais comuns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvH_STAdNzXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivosd, rotulos = processa_diretorios(['lingspam_public/lemm_stop/part1', 'lingspam_public/lemm_stop/part2', 'lingspam_public/lemm_stop/part3'])\n",
        "palavra_id, id_palavra = gera_dicionario(arquivosd, 3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYAPGTWDcaOs",
        "colab_type": "text"
      },
      "source": [
        "Exemplo das palavras extraídas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar5eBaaLcciV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8362c336-8bb9-4b0c-a018-3c16d232d350"
      },
      "source": [
        "id_palavra[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['language',\n",
              " 'university',\n",
              " 'one',\n",
              " 'linguistic',\n",
              " 'address',\n",
              " 'mail',\n",
              " 'work',\n",
              " 'order',\n",
              " 'send',\n",
              " 'word']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUSYOm-ej0sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44fd5a7f-645a-46fc-f1f6-9053c9fa5d05"
      },
      "source": [
        "id_palavra[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'one'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnlYCuF9chaW",
        "colab_type": "text"
      },
      "source": [
        "## Classificação:\n",
        "\n",
        "De posse deste dicionário, é possível criar um vetor de características para cada mensagem.\n",
        "\n",
        "Como descrito acima, este vetor contém na sua $i$-gésima posição a quantidade de vezes que a palavra de índice $i$ aparece.\n",
        "\n",
        "O código abaixo recebe um caminho para um arquivo e um dicionário de palava->índice e retorna este vetor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR0CEgTIPUxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gera_vetor(arquivo, palavra_id): \n",
        "    vetor = np.zeros(len(palavra_id))\n",
        "    with open(arquivo) as a:\n",
        "      for i, l in enumerate(a):\n",
        "        if i == 2:\n",
        "          palavras = l.split()\n",
        "          for palavra in palavras:\n",
        "            if palavra in palavra_id:\n",
        "              vetor[palavra_id[palavra]] += 1\n",
        "    return vetor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSaC06ZldO-H",
        "colab_type": "text"
      },
      "source": [
        "Exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnWIZR8odQCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31f6eac-987b-43f0-a273-78dac3588442"
      },
      "source": [
        "gera_vetor('lingspam_public/lemm_stop/part4/6-241msg3.txt', palavra_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_EPFAMPdcAN",
        "colab_type": "text"
      },
      "source": [
        "Você deve construir um classificador do tipo Naive Bayes para este conjunto de mensagens.\n",
        "Use o objeto ```MultinomialNB``` da biblioteca SKLearn.\n",
        "\n",
        "O método ```fit(X, y)``` recebe uma matriz em ```X``` na qual cada linha é um vetor característico de um objeto e um vetor ```y``` no qual cada coeficiente é a classificação correta do objeto correspondente (ou seja, ```y``` tem tantos coeficientes quanto ```X``` tem de linhas).\n",
        "\n",
        "Monte a sua matriz ```X``` e o seu vetor ```y``` com os arquivos dos diretórios ```lingspam_public/lemm_stop/part4```, ```lingspam_public/lemm_stop/part5```, ```lingspam_public/lemm_stop/part6``` e ```lingspam_public/lemm_stop/part7```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXuH04dPnsDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f2aec01-7632-4aae-abd7-b27d66e7520b"
      },
      "source": [
        "arquivosd, rotulos = processa_diretorios([\n",
        "                                          'lingspam_public/lemm_stop/part4',\n",
        "                                          'lingspam_public/lemm_stop/part5',\n",
        "                                          'lingspam_public/lemm_stop/part6',\n",
        "                                          'lingspam_public/lemm_stop/part7'])\n",
        "dados = []\n",
        "for a in arquivosd:\n",
        "  dados.append(gera_vetor(a, palavra_id).tolist())\n",
        "\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(dados, rotulos)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5QxEG72ec2g",
        "colab_type": "text"
      },
      "source": [
        "## Avaliação do Classificador.\n",
        "\n",
        "O método ```predict(X)``` do classificador recebe uma matriz ```X``` na qual cada linha é um vetor característico de um objeto.\n",
        "Ele retorna um vetor com a classificação prevista para cada objeto.\n",
        "\n",
        "Mostre a matriz de confusão do classificador que você montou acima quando aplicado às mensagens no diretório ```lingspam_public/lemm_stop/part8```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_73RUl6JeTHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9137ebba-aa30-4067-ab77-2b1a64f318f7"
      },
      "source": [
        "arquivos_teste, rotulos_teste = processa_diretorios(['lingspam_public/lemm_stop/part8'])\n",
        "dados_teste = []\n",
        "for a in arquivos_teste:\n",
        "  dados_teste.append(gera_vetor(a, palavra_id).tolist())\n",
        "\n",
        "predicoes = modelo.predict(dados_teste)\n",
        "\n",
        "confusion_matrix(rotulos_teste, predicoes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[233,   8],\n",
              "       [  0,  48]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}