{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHK6DyunSbs4"
   },
   "source": [
    "# Trabalho #4 - Gerador de dados\n",
    "\n",
    "Nesse trabalho você vai treinar uma RNA para realizar uma tarefa de classificação de múltiplas classes. A tarefa consiste em identificar três tipos de animais: gato, cachorro e panda. Esse problema foi proposto no Kaggle em 2019 e pode ser acessado em https://www.kaggle.com/ashishsaxena2209/animal-image-datasetdog-cat-and-panda.\n",
    "\n",
    "A diferença principal desse trabalho em relação aos outros já realizados até o momento, é a utilização de imagens reias, que possuem dimensões e proporções diferentes, objetos não centrados, luminosidades diferentes etc.\n",
    "\n",
    "Nesse trabalho para processar as imagens de forma a normalizá-las e redimensioná-las para que tenham dimensão uniforme são usados geradores de dados. Além disso, para eliminar problemas de \"overfitting\" é também parte desse trabalho treinar uma RNA com geração artificial de dados.\n",
    "\n",
    "Esse trabalho é dividio nas seguintes etapas:\n",
    "\n",
    "1. Explorar as imagens do conjunto de dados;\n",
    "2. Construir e treinar uma RNA para identificar o animal mostrado na imagem;\n",
    "3. Treinar uma nova RNA para identificar o animal mostrado usando geração artificial de dados;\n",
    "4. Avaliar e comparar o desempenho das duas RNAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoWDGuZLFTWE"
   },
   "source": [
    "## Coloque o seu nome aqui:\n",
    "\n",
    "Nome:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L7r2zdl64Hg"
   },
   "source": [
    "## 1. Imagens do conjunto de dados\n",
    "\n",
    "A primeira etapa do trabalho é carregar o conjunto de dados, que consiste em um arquipo tipo zip de 3.000 fotos no formato JPG de gatos, cães e pandas, e extrair localmente no diretório `tmp`.\n",
    "\n",
    "**NOTA:** As 3.000 imagens usadas neste trabalho foram extraídas do conjunto de dados \"Dogs-Cats-Pandas\", disponível no Kaggle, no link https://www.kaggle.com/ashishsaxena2209/animal-image-datasetdog-cat-and-panda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6K0yAxfFTWH"
   },
   "source": [
    "### Carregar arquivo de dados para o Colab\n",
    "\n",
    "Execute a célula abaixo para carregar as imagens para o seu Colab. Após a execução dessa célula as imagens estão no arquivo `cats_dogs_pandas.zip` no diteório `tmp` do seu ambiente do Colab.\n",
    "\n",
    "**Importante:** se você estiver usando o notebook Jupiter do Anaconda essa célula não deve ser executada e o arquivo compactado com os dados deve estar no subdiretório `tmp` do diretório onde se encontra o seu notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXZT2UsyIVe_",
    "outputId": "018c0664-853e-4560-ead9-30104ae25287",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1BSbYML5rw6srpxNEd9mdVhzfkS605Sfd -O /tmp/cat_dog_panda.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brUxyTpYZHy"
   },
   "source": [
    "Execute a célula abaixo para descompactar o arquivo com as imagens. O código usa a biblioteca `os`, que possui funções do sistema operacional que fornecem acesso ao sistema de arquivos, e a biblioteca zipfile que permite descompactar arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLy3pthUS0D2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/cat_dog_panda.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-qUPyfO7Qr8"
   },
   "source": [
    "O conteúdo do arquivo `cat_dog_panda.zip` é extraído para o diretório `content/tmp/cat_dog_panda`, que contém os subdiretórios `train`, `val` e `test` com as imagens dos conjuntos de dados de treinamento, validação e teste.\n",
    "\n",
    "Lembre que, conforme visto na aula, o gerador `ImageDataGenerator` do Keras identifica e cataloga as imagens automaticamente a partir dos subdiretórios onde elas se encontram. Assim, por exemplo, no diretório `train` existe um diretório `cats`, um ditetório `dogs` e outro `pandas`. O `ImageGenerator` rotula automaticamente as imagens, simplificando a etapa de codificação dos dados.\n",
    "\n",
    "**Importante:** \n",
    "\n",
    "O Keras fornece rótulos para classes de acordo com a ordem que os subdiretórios estão nos diretórios `train`, `val` e `pandas`. Assim, se o subdiretório `cats` é o primeiro então, os gatos serão a classe 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T-N5--iFTWY"
   },
   "source": [
    "### Exercíco #1: Definir os nomes dos diretórios\n",
    "\n",
    "Complete a célula de código abaixo para criar variáveis com os nomes dos diretórios e subdiretórios com as imagens de treinamento, validação e teste. Para isso utilize a  função `path.join(diretório_base, subdiretório)` da biblioteca `os` (https://docs.python.org/2/library/os.path.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLZKVtE0dSfk",
    "outputId": "c15f6f40-ac5f-4e58-be52-3f37fbe36f1e"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: definir nomes dos diretórios\n",
    "\n",
    "import os\n",
    "\n",
    "# Nome do diretório base\n",
    "base_dir = '/tmp/cat_dog_panda'\n",
    "\n",
    "# Path dos diretórios de treinamento, validação e teste\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Path dos subdiretórios com as imagens do dados de treinamento\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Path dos subdiretórios com as imagens do dados de validação\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Path dos subdiretórios com as imagens do dados de teste\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "print('Subdiretório de imagens de gatos para treinamento =', train_cats_dir)\n",
    "print('Subdiretório de imagens de cães para treinamento =', train_dogs_dir)\n",
    "print('Subdiretório de imagens de pandas para treinamento =', train_pandas_dir)\n",
    "print('Subdiretório de imagens de gatos para validação =', val_cats_dir)\n",
    "print('Subdiretório de imagens de cães para validação =', val_dogs_dir)\n",
    "print('Subdiretório de imagens de pandas para validação =', val_pandas_dir)\n",
    "print('Subdiretório de imagens de gatos para teste =', test_cats_dir)\n",
    "print('Subdiretório de imagens de cães para teste =', test_dogs_dir)\n",
    "print('Subdiretório de imagens de pandas para teste =', test_pandas_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2n_dOMFFTWf"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Subdiretório de imagens de gatos para treinamento = /tmp/cat_dog_panda/train/cats\n",
    "    Subdiretório de imagens de cães para treinamento = /tmp/cat_dog_panda/train/dogs\n",
    "    Subdiretório de imagens de pandas para treinamento = /tmp/cat_dog_panda/train/pandas\n",
    "    Subdiretório de imagens de gatos para validação = /tmp/cat_dog_panda/val/cats\n",
    "    Subdiretório de imagens de cães para validação = /tmp/cat_dog_panda/val/dogs\n",
    "    Subdiretório de imagens de pandas para validação = /tmp/cat_dog_panda/val/pandas\n",
    "    Subdiretório de imagens de gatos para teste = /tmp/cat_dog_panda/test/cats\n",
    "    Subdiretório de imagens de cães para teste = /tmp/cat_dog_panda/test/dogs\n",
    "    Subdiretório de imagens de pandas para teste = /tmp/cat_dog_panda/test/pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuBYtA_Zd8_T"
   },
   "source": [
    "### Exercíco #2: Criar listas dos arquivos de imagens de treinamento e verificar número de exemplos\n",
    "\n",
    "Modifique a célula de código abaixo para criar listas com os nomes dos arquivos nos subdiretórios `cats` e` dogs` `train` do diretório de treinamento. Esses nomes serão utilizados para acessar as imagens de forma a permitir a sua visualização e análise. Para realizar essa tarefa utilize a função `listdir(diretório)` da biblioteca `os` (https://docs.python.org/2/library/os.html?highlight=listdir#os.listdir). \n",
    "\n",
    "Após criar essa lista, verifique o número total de imagens em cada subdiretório dos diretórios de treinamento, validação e teste. Para isso use a função `len` do python para calcular o número de elementos de uma lista.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PIP1rkmeAYS",
    "outputId": "b3761f25-bbd3-4b3c-c7af-7e80089608dd"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Criar lista dos arquivos dos subdiretórios do diretório de treinamento e verificar número de exemplos\n",
    "\n",
    "# Listas de arquivos imagens de treinamento\n",
    "# Incluir seu código aqui\n",
    "#train_cat_fnames \n",
    "#train_dog_fnames\n",
    "#train_panda_fnames \n",
    "\n",
    "# Calcular número de exemplos de treinamento \n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Calcular número de exemplos de validação, usar len(os.lisdir(diretório))\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Calcular número de exemplos de teste, usar len(os.lisdir(diretório))\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "print('Nomes dos arquivos de gatos (5 primeiros):', train_cat_fnames[:5])\n",
    "print('Nomes dos arquivos de cães (5 primeiros):', train_dog_fnames[:5])\n",
    "print('Nomes dos arquivos de pandas (5 primeiros):', train_panda_fnames[:5])\n",
    "\n",
    "print('Total imagens treinamento gatos:', len_cat_train)\n",
    "print('Total imagens treinamento cães:', len_dog_train)\n",
    "print('Total imagens treinamento pandas:', len_panda_train)\n",
    "\n",
    "print('Total imagens validação gatos :', len_cat_val)\n",
    "print('Total imagens validação cães:', len_dog_val)\n",
    "print('Total imagens validação pandas:', len_panda_val)\n",
    "\n",
    "print('Total imagens teste gatos:', len_cat_test)\n",
    "print('Total imagens teste cães:', len_dog_test)\n",
    "print('Total imagens teste pandas:', len_panda_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6h0DnXPFTWo"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Nomes dos arquivos de gatos (5 primeiros): ['cats_00800.jpg', 'cats_00998.jpg', 'cats_00403.jpg', 'cats_00515.jpg', 'cats_00982.jpg']\n",
    "    Nomes dos arquivos de cães (5 primeiros): ['dogs_00365.jpg', 'dogs_00523.jpg', 'dogs_00763.jpg', 'dogs_00425.jpg', 'dogs_00568.jpg']\n",
    "    Nomes dos arquivos de pandas (5 primeiros): ['panda_00637.jpg', 'panda_00774.jpg', 'panda_00874.jpg', 'panda_00425.jpg', 'panda_00791.jpg']\n",
    "    Total imagens treinamento gatos: 660\n",
    "    Total imagens treinamento cães: 660\n",
    "    Total imagens treinamento pandas: 660\n",
    "    Total imagens validação gatos : 170\n",
    "    Total imagens validação cães: 170\n",
    "    Total imagens validação pandas: 170\n",
    "    Total imagens teste gatos: 170\n",
    "    Total imagens teste cães: 170\n",
    "    Total imagens teste pandas: 170\n",
    "    \n",
    "Observe que existem 660 imagens de treinamento, 170 imagens de validação e 170 imagens de teste para cada animal. Ou seja, existem um total de 1980 imagens de treinamento, 510 imagens de validação e 510 imagens de teste.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3WZABE9eX-8"
   },
   "source": [
    "### Visalização das imagens\n",
    "\n",
    "Execute a célula abaixo para visualizar algumas imagens de gatos, cães e pandas de treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "Wpr8GxjOU8in",
    "outputId": "233dc796-d4c7-47cb-f3ec-34f90308e98b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Número de linhas e colunas do arranjo para mostrar as imagens\n",
    "nrows = 6\n",
    "ncols = 4\n",
    "\n",
    "# Define figura do matplotlib e define o tamanho para ser mostrada \n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 16)\n",
    "\n",
    "pic_index = 8\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "                for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "                for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
    "next_panda_pix = [os.path.join(train_pandas_dir, fname) \n",
    "                for fname in train_panda_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix+next_panda_pix):\n",
    "    # Define índice da imagem\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Não mostra eixos ou grids\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVCfs-1LFTWs"
   },
   "source": [
    "Observe que as imagens possuem formas e proporções diferente, dessa forma, antes de treinar uma rede Neural com essas imagens tem que ajustar as suas dimensões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImPr6DcVFTWt"
   },
   "source": [
    "## 2. Pré-processamento dos dados\n",
    "\n",
    "Nesse trabalho, vamos utilizar três geradores de dados para carregar as imagens dos diretórios de origem e convertê-las em tensores `float32`. Teremos um gerador para as imagens de treinamento, um para as imagens de validação e outro para as imagens de teste. Os geradores devem produzir lotes de 30 imagens, com dimensão 150x150, para classificação multiclasse.\n",
    "\n",
    "Como você já sabe, os dados de entrada para a RNA devem ser normalizados, no caso de imagens o mais comum é ter as imagens normalizadas de forma a transformar os valores dos pixels, originalmente um número inteiro no intervalo [0, 255], para um número real no intervalo [0, 1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiUNWb30FTWt"
   },
   "source": [
    "### Exercício #3: Pré-processamento de dados\n",
    "\n",
    "Para criar e configurar os três geradores você vai usar a classe `ImageDataGenerator` do Keras  com o parâmetro `rescale`. A classe `ImageDataGenerator` permite instanciar geradores de lotes de imagens, juntamente com os seus rótulos, usando o método `flow_from_directory (diretório)`. Esses geradores podem então ser usados com os métodos do Keras para treinamento, avaliação e previsão: `fit`,` evaluate` e `predict`.\n",
    "\n",
    "Os três geradores devem ser configurados e instanciados da seguinte forma:\n",
    "\n",
    "- Normalização dos pixles para valores no intervalo [0, 1]\n",
    "- Tamanho do lote = 30\n",
    "- Tipo de problema: classificação multiclasse\n",
    "- Dimensão das imagens: 150x150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPY1zrZTFTWu",
    "outputId": "c020bcad-4de9-4931-9bcd-51fa799f6616"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: criar e instanciar os geradores de dados de treinamento, validação e teste\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dimensão das imagens\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Cria gerador usando a classe ImageDataGenerator que normaliza imagens\n",
    "# Incluir seu código aqui\n",
    "#datagen = \n",
    "\n",
    "# Instancia gerador de imagens de treinamentocom o método flow_from (utilize a variável que define o diretório de dados de treinamento)\n",
    "# Incluir seu código aqui\n",
    "#train_generator \n",
    "\n",
    "\n",
    "# Instancia gerador de imagens de validação (utilize a variável que define o diretório de dados de validação)\n",
    "# Incluir seu código aqui\n",
    "#val_generator \n",
    "\n",
    "\n",
    "# Instancia gerador de imagens de teste (utilize a variável que define o diretório de dados de teste)\n",
    "# Incluir seu código aqui\n",
    "#test_generator \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQhDdYPEZvJt"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Found 1980 images belonging to 3 classes.\n",
    "    Found 510 images belonging to 3 classes.\n",
    "    Found 510 images belonging to 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oqBkNBJmtUv"
   },
   "source": [
    "## 3. Construir e treinar uma RNA para classificação\n",
    "\n",
    "Para identificar o animal mostrado na imagem você utilizar uma RNA convolucional relativamente simples. Na medida em que as imagens estão em arquivos e possuem dimensões diferentes é necessário usar um gerador de dados para o treinamento da rede. \n",
    "\n",
    "Nessa etapa do trabalho você vai configurar uma RNA convolucional, criar geradores de dados para carregar e processar as imagens, e finalmente treinar a RNA.\n",
    "\n",
    "\n",
    "### Exercício #4: Criação da RNA\n",
    "\n",
    "Para resolver esse problema de classificação multiclasse, você vai usar uma RNA com 3 camadas convolucionais, seguidas de camadas \"max-pooling\", e 2 camadas densas, com as seguintes características:\n",
    "\n",
    "- Dimensão das imagens: 150x150x3;\n",
    "- Primeira camada convolucional: número de filtros 32, dimensão do filtro 3, função de ativação ReLu;\n",
    "- Segunda camada convolucional: número de filtros 64, dimensão do filtro 3, função de ativação ReLu;\n",
    "- Terceira camada convolucional: número de filtros 128, dimensão do filtro 3, função de ativação ReLu;\n",
    "- Camadas de max-pooling: dimensão da janela 2, \"stride\" 2; \n",
    "- Primeira camada densa: número de neurônios 256, função de ativação ReLu;\n",
    "- Camada de saída: número de neurônio 3, função de ativação softmax.\n",
    "\n",
    "Ressalta-se que após cada camada convolucional tem-se uma camada de max-pooling.\n",
    "\n",
    "Na célula abaixo crie uma funçao que configura uma RNA com as características acima. Não se esqueça de incluir a camada de \"flattening\" entre a última camada de max-pooling e a primeira camada densa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PixZ2s5QbYQ3"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Função para criar RNA convolucional para classificação multiclasse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "def build_model(img_size):\n",
    "    \n",
    "    # Criação e configuração da RNA\n",
    "    # Incluir seu código aqui\n",
    "    #\n",
    "   \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWvU7q7YOzVw",
    "outputId": "3959d4da-0a87-4deb-a6a6-58465ec41778"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Criar RNA convolucional para classificação dos animais\n",
    "\n",
    "# Define dimensão das imagens\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Criação da RNA usando a função buil_model\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "rna.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B27wnbcIFTW_"
   },
   "source": [
    "**Saída esperada:**\n",
    "    \n",
    "    Model: \"sequential\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
    "    _________________________________________________________________\n",
    "    flatten (Flatten)            (None, 36992)             0         \n",
    "    _________________________________________________________________\n",
    "    dense (Dense)                (None, 256)               9470208   \n",
    "    _________________________________________________________________\n",
    "    dense_1 (Dense)              (None, 3)                 771       \n",
    "    =================================================================\n",
    "    Total params: 9,564,227\n",
    "    Trainable params: 9,564,227\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLnqt3QbFTXB"
   },
   "source": [
    "### Exercício #5: Compilação e treinamento da RNA\n",
    "\n",
    "Agora você vai treinar a sua RNA usando o método de otimização Adams. Assim, na célula abaixo, compile e treine a sua RNA usando os seguinte hiperparâmetros:\n",
    "\n",
    "- método de otimização: Adam;\n",
    "- taxa de aprendizagem = 0.001;\n",
    "- número de épocas = 20;\n",
    "- verbose = 2.\n",
    "\n",
    "Cuidado para definir os parâmetros `steps_per_epoch` e `validation_steps` de forma a utilizar todos as iamgens de treinamento e de validação. Lembre que temos 1980 imagens de treinamento, 510 imagens de validação e o tamanho dos lotes é de 30 imagens. \n",
    "\n",
    "Para treinamento da RNA, utilize o método `fit_generator` e os geradores de dados de treinamento e validação. \n",
    "\n",
    "Não se esqueça de definir a função de custo apropriada para classificação multiclasse e escolher a métrica exatidão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3VaMcawFTXF",
    "outputId": "15f0512f-3a4c-4026-b179-8f21a46884a8"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: compilar e treinar a RNA\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Comiplação da RNA\n",
    "# Incluir seu código aqui\n",
    "\n",
    "# Treinamento da RNA\n",
    "# Incluir seu código aqui\n",
    "#history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHzspBMSFTXT"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Epoch 1/20\n",
    "    66/66 - 9s - loss: 0.9156 - accuracy: 0.5429 - val_loss: 0.7954 - val_accuracy: 0.5784\n",
    "    Epoch 2/20\n",
    "    66/66 - 9s - loss: 0.6867 - accuracy: 0.6515 - val_loss: 0.6980 - val_accuracy: 0.6686\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    Epoch 19/20\n",
    "    66/66 - 9s - loss: 4.3007e-04 - accuracy: 1.0000 - val_loss: 2.1578 - val_accuracy: 0.6863\n",
    "    Epoch 20/20\n",
    "    66/66 - 9s - loss: 3.3048e-04 - accuracy: 1.0000 - val_loss: 2.1160 - val_accuracy: 0.7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9zbq2h7FTXT"
   },
   "source": [
    "### Visualização dos resultados de treinamento\n",
    "\n",
    "Execute a célula abaixo para visualizar a função de custo e a exatidão em função do número de épocas de treinamento e verificar se o treinamento foi satisfatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "wQKvq50TFTXU",
    "outputId": "ca993a00-3427-47f7-97e7-6e6b05625b98"
   },
   "outputs": [],
   "source": [
    "# Recupera resultados de treinamento do dicinário history\n",
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocas   = range(len(acc)) \n",
    "\n",
    "# Gráfico dos valores da função de custo\n",
    "plt.plot(epocas, loss, 'r', label='Custo - treinamento')\n",
    "plt.plot(epocas, val_loss, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocas, acc, 'r', label='exatidao- treinamento')\n",
    "plt.plot(epocas, val_acc, 'b', label='exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAlQ57ANFTXb"
   },
   "source": [
    "### Avaliação do desempenho da RNA\n",
    "\n",
    "Execute a célula abaixo para calcular a função de custo e a métrica de forma a avaliar o desempenho da RNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXYFDbv4FTXc",
    "outputId": "7dc26236-5354-4b85-b993-71dbfbff425a"
   },
   "outputs": [],
   "source": [
    "# Calcula a função de custo e a métrica para os dados de treinamento, validação e teste\n",
    "custo_metrica_train = rna.evaluate(train_generator, steps=66) \n",
    "custo_metrica_val = rna.evaluate(val_generator, steps=17) \n",
    "custo_metrica_test = rna.evaluate(test_generator, steps=17) \n",
    "\n",
    "print(custo_metrica_train)\n",
    "print(custo_metrica_val)\n",
    "print(custo_metrica_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzUE0CbCsC5G"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    [0.0025995231699198484, 1.0]\n",
    "    [2.1967246532440186, 0.6921568512916565]\n",
    "    [2.334252119064331, 0.6980392336845398]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7XgVutGFTXi"
   },
   "source": [
    "### Análise dos resultados\n",
    "\n",
    "Como você pode observar essa RNA está com problema de \"overfitting\". Isso pode ser observado de duas formas:\n",
    "\n",
    "1) O comportamento da função de custo e da métrica para os dados de validação e para os dados de treinamento. Enquanto que a tendência da função de custo é de diminuir e da métrica (exatidão) é de aumentar para os dados de treinamento durante todo o treinamento, para os dados de validação após algumas épocas, a função de custo aumenta e a exatidão diminui. Esse comportamento é tipico de problemas de \"overfitting\".\n",
    "\n",
    "2) Enquanto que a exatidão para os dados de treinamento é de 100%, para os dados de validação é de apenas cerca de 70%.\n",
    "\n",
    "3) **Importante:** Observe que não adianta treinar a RNA por um número maior de épocas que o seu desempenho não vai melhorar.\n",
    "\n",
    "Como temos um número relativamente pequeno de exemplos de treinamento (1.980) o problema de \"overfitting\" é quase impossível de evitar, mas temos que eliminá-lo senão a nossa RNA não tem nenhuma utilidade. Como já visto, \"overfitting\" ocorre quando uma RNA é treinada com poucos exemplos e, assim, aprende padrões que não generalizam para novos dados, ou seja, quando a RNA começa a usar caracteríticas irrelevantes presentes nos dados para fazer previsões. Por exemplo, se você, como humano, vê apenas três imagens de pessoas que são lenhadores e três imagens de pessoas que são marinheiros, e entre elas a única pessoa que usa boné é um lenhador, você pode começar a pensar que usar boné é um sinal de ser lenhador em oposição a um marinheiro. Ao fazer isso, você faria um classificador de lenhador/marinheiro muito deficiente.\n",
    "\n",
    "Com já visto o problema de \"overfitting\" é um dos principais problemas do aprendizado de máquina. Dado que estamos ajustando os parâmetros de nosso modelo para um determinado conjunto de dados, como podemos garantir que as representações aprendidas pelo modelo sejam aplicáveis a dados nunca vistos antes? Como evitamos aprender coisas específicas presentes nos dados de treinamento? \n",
    "\n",
    "Nós já vimos e testamos alguns métodos de regularização. No restante desse trabalho você vai usar geração artifical de dados (\"data augmentation\") para tentar minimizar o problema de \"overfitting\" dessa RNA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6vSHzPR2ghH"
   },
   "source": [
    "### Teste da RNA com novas imagens\n",
    "\n",
    "O código da célula abaixo permite que você escolher um ou mais arquivos que estão no seu computador, carregar esses arquivos e utilizar a sua RNA para prever se a imagem carregada mostra um gato, ou um cão, ou um panda. Observa-se que esse código somente funciona se você estiver utilizando o Colab.\n",
    "\n",
    "**Observação.** Um bom site da internet para obter imagens em geral é o pixabay (https://pixabay.com/pt/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "DoWp43WxJDNT",
    "outputId": "166f02ae-f09a-4fe2-e328-d5fe02c6412b"
   },
   "outputs": [],
   "source": [
    "# Importa bibliotecas e funções\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Função do Colab para carregar arquivos\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    path = '/content/' + fn\n",
    "    # Carrega imagens usando função do Keras\n",
    "    img = image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "    # Mostra imagem\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "  \n",
    "    # Converte imagem para tensor e acrescenta eixo dos exemplos\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "  \n",
    "    # Calcula previsão da RNA e determina classe\n",
    "    y_prev = rna.predict(images, batch_size=10)\n",
    "    classe = np.argmax(y_prev)\n",
    "  \n",
    "    # Apresenta classe identificada\n",
    "    if classe==0:\n",
    "        print(fn + \" é um gato\")\n",
    "    elif classe==1:\n",
    "        print(fn + \" é um cão\")\n",
    "    else:\n",
    "        print(fn + \" é um panda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2JjL4XKFTXr"
   },
   "source": [
    "## 4. Treinamento com geração artificial de dados\n",
    "\n",
    "Para treinar a sua RNA com \"data augmentation\" você precisa de um gerador de dados de treinamento que além de carregar as imagens, normalizá-las, redimensioná-las e convertê-las em tensores de números reais, deve também modificá-las aplicando transformações aleatórias. Isso perimte que a RNA seja treinada sempre com novas imagens, mas obviamente que são imagens criadas artificialmente baseadas nas imagens originais de treinamento. \n",
    "\n",
    "Como não se deve realizar transformações das imagens de validação e teste, podemos utilizar para carregar e pré-processar essas imagens os mesmos geradores que criamos anteriormente, ou seja, `val_generator` e `test_generator`. Dessa forma precisamos criar e instanciar somente um novo gerador para as imagens de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpTh7Bi3FTXs"
   },
   "source": [
    "### Exercício #6: Gerador de dados de treinamento com \"data augmentation\"\n",
    "\n",
    "Para criar e configurar o gerador de imagens de treinamento com \"data augmentation\" você deve usar o mesmo procedimento realizado no exercício #3. Esse gerador devem ser configurado e instanciado da seguinte forma:\n",
    "\n",
    "- Normalização dos pixles para valores no intervalo [0, 1]\n",
    "- Tamanho do lote = 30\n",
    "- Tipo de problema: classificação multiclasse\n",
    "- Dimensão das imagens: 150x150\n",
    "- Redução/ampliação de 20%\n",
    "- Angulo de rotação no intervalo de +-20 graus\n",
    "- Translação vertical e horizontal de 0,2\n",
    "- Inversão horizontal\n",
    "- Alteração do brilho entre 0,5 e 1,1\n",
    "- Método de preenchimento de lacunas: borda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkpFLKvFFTXt",
    "outputId": "760199c6-1f9b-45ad-f27a-a078414c1b39"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: compilar e treinar a RNA\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define dimensão das imagens\n",
    "img_size_gen = (150, 150)\n",
    "\n",
    "# Criação do gerador de dados de treinamento com \"data augmentation\"\n",
    "# Incluir seu código aqui\n",
    "#aug_datagen = \n",
    "\n",
    "# Instancia gerador de imagens de treinamento (utilize a variável que define o diretório de dados de treinamento)\n",
    "# Incluir seu código aqui\n",
    "#aug_train_generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIOlCOKIFTXy"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Found 1980 images belonging to 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vVni394FTXz"
   },
   "source": [
    "### Exercício #7: Teste do gerador com \"data augmentation\"\n",
    "\n",
    "Modifique a célula abaixo para executar o gerador de imagens com \"data augmentation\" de forma a  criar um lote de imagens transformadas. Utilize para isso o método `next()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWwqxTXnFTX0",
    "outputId": "a7e3353d-112b-4bc3-8f42-2b918290797c"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: testar gerador com \"data augmentation\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Inicializa tensores de imagens e saídas\n",
    "imagens, y = [], []\n",
    "\n",
    "# Executa o gerador uma única vez\n",
    "# Incluir seu código aqui\n",
    "#imagens, y = \n",
    "\n",
    "\n",
    "# Tranforma a saída da rede que é uma probabilidade de mostrar um dos animais na classe prevista.\n",
    "# Para isso use a função argmax com axis=1.\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Apresenta as classes previstas\n",
    "print('Img No. - Classe (one_hot) - Classe (inteiro)')\n",
    "for i in range(classes.shape[0]):\n",
    "    print(i, y[i], classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbSIJMAoFTX5"
   },
   "source": [
    "**Saída esperada:**\n",
    "    \n",
    "    Img No. - Classe (one_hot) - Classe (inteiro)\n",
    "    0 [0. 1. 0.] 1\n",
    "    1 [1. 0. 0.] 0\n",
    "    2 [1. 0. 0.] 0\n",
    "    3 [1. 0. 0.] 0\n",
    "    4 [0. 0. 1.] 2\n",
    "    5 [0. 0. 1.] 2\n",
    "    6 [1. 0. 0.] 0\n",
    "    7 [0. 1. 0.] 1\n",
    "    8 [1. 0. 0.] 0\n",
    "    9 [0. 1. 0.] 1\n",
    "    10 [0. 0. 1.] 2\n",
    "    11 [1. 0. 0.] 0\n",
    "    12 [0. 1. 0.] 1\n",
    "    13 [0. 0. 1.] 2\n",
    "    14 [1. 0. 0.] 0\n",
    "    15 [0. 0. 1.] 2\n",
    "    16 [1. 0. 0.] 0\n",
    "    17 [1. 0. 0.] 0\n",
    "    18 [0. 0. 1.] 2\n",
    "    19 [0. 0. 1.] 2\n",
    "    20 [1. 0. 0.] 0\n",
    "    21 [0. 0. 1.] 2\n",
    "    22 [0. 1. 0.] 1\n",
    "    23 [1. 0. 0.] 0\n",
    "    24 [0. 0. 1.] 2\n",
    "    25 [0. 0. 1.] 2\n",
    "    26 [0. 1. 0.] 1\n",
    "    27 [0. 0. 1.] 2\n",
    "    28 [0. 1. 0.] 1\n",
    "    29 [0. 0. 1.] 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXpvdnUvFTX6"
   },
   "source": [
    "### Visualização das imagens transformadas\n",
    "\n",
    "Execute a célula abaixo para visualizar o lote de imagens transformadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sCdpNCI7FTX7",
    "outputId": "8483fdb1-af3e-4ccb-c48d-b5c77d91c680"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 32))\n",
    "\n",
    "nrows = 10\n",
    "ncols = 3\n",
    "\n",
    "print('Classes das imagens =', classes)\n",
    "\n",
    "i = 0\n",
    "for img in imagens:\n",
    "# Set up subplot; subplot indices start at 1\n",
    "    plt.subplot(nrows, ncols, i + 1)\n",
    "    plt.imshow(img)\n",
    "    i = i + 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68Ha7vIdFTYD"
   },
   "source": [
    "### Exercício #8: Compilação e treinamento da RNA\n",
    "\n",
    "Agora você vai treinar a sua RNA usando o método de otimização Adams e o gerador de dados com \"data augmentation\". Assim, na célula abaixo, crie uma nova RNA, compile e treine usando os seguintes hiperparâmetros:\n",
    "\n",
    "- método de otimização: Adam;\n",
    "- taxa de aprendizagem = 0.001;\n",
    "- número de épocas = 30;\n",
    "- verbose = 2.\n",
    "\n",
    "Para esse treinamento com \"data augmentation\" oberve os seguintes pontos:\n",
    "\n",
    "- Cuidado para definir os parâmetros `steps_per_epoch` e `validation_steps` de forma a utilizar todos as imagens de treinamento e de validação. Lembre que temos 1980 imagens de treinamento, 510 imagens de validação e o tamanho dos lotes é de 30 imagens. \n",
    "- Para treinar a RNA, utilize o método `fit_generator`, o gerador de dados de treinamento com \"data augmentation, e o gerador de dados de validação definidos anteriormente. \n",
    "- Utilize a mesma função de custo e a mesma métrica usadas anteriormentes.\n",
    "\n",
    "**Importante:** Com \"data augmentation\" temos que treinar a RNA por um número maior de épocas para que ela seja capaz de generalizar os dados de treinamento de forma adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoRdWjAEFTYE",
    "outputId": "62eac57a-e4bb-4f0b-a813-25a090493093"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Criar, compilar e treinar a RNA com \"data augmentation\"\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Cria RNA usando a função build_model\n",
    "# Incluir seu código aqui\n",
    "#rna2 =  \n",
    "\n",
    "# Comiplação da RNA\n",
    "# Incluir seu código aqui\n",
    "#\n",
    "\n",
    "# Treinamento da RNA\n",
    "# Incluir seu código aqui\n",
    "#history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8PswlJ__sEq"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Epoch 1/30\n",
    "    66/66 - 19s - loss: 0.9874 - accuracy: 0.4939 - val_loss: 0.7968 - val_accuracy: 0.5843\n",
    "    Epoch 2/30\n",
    "    66/66 - 19s - loss: 0.8382 - accuracy: 0.5823 - val_loss: 0.7492 - val_accuracy: 0.5843\n",
    "    Epoch 3/30\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    Epoch 29/30\n",
    "    66/66 - 19s - loss: 0.4986 - accuracy: 0.7566 - val_loss: 0.6341 - val_accuracy: 0.7824\n",
    "    Epoch 30/30\n",
    "    66/66 - 19s - loss: 0.4823 - accuracy: 0.7773 - val_loss: 0.6664 - val_accuracy: 0.7745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY9KAEazFTYO"
   },
   "source": [
    "### Visualização dos resultados de treinamento\n",
    "\n",
    "Execute a célula abaixo para visualizar a função de custo e a exatidão em função do número de épocas de treinamento e verificar se o treinamento foi satisfatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "CPjQnAMWFTYP",
    "outputId": "0994d22b-1000-443c-b1e5-4c78e489f9b2"
   },
   "outputs": [],
   "source": [
    "# Recupera resultados de treinamento do dicinário history\n",
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocas   = range(len(acc)) \n",
    "\n",
    "# Gráfico dos valores da função de custo\n",
    "plt.plot(epocas, loss, 'r', label='Custo - treinamento')\n",
    "plt.plot(epocas, val_loss, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocas, acc, 'r', label='exatidao- treinamento')\n",
    "plt.plot(epocas, val_acc, 'b', label='exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AVejGw7FTYU"
   },
   "source": [
    "### Avaliação do desempenho da RNA\n",
    "\n",
    "Execute a célula abaixo para calcular a função de custo e a métrica de forma a avaliar o desempenho da RNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGX2eEc_FTYV",
    "outputId": "95576781-a985-47c9-ce85-1f6064c2c66e"
   },
   "outputs": [],
   "source": [
    "# Calcula a função de custo e a métrica para os dados de treinamento, validação e teste\n",
    "custo_metrica_train = rna2.evaluate(train_generator, steps=66) \n",
    "custo_metrica_val = rna2.evaluate(val_generator, steps=17) \n",
    "custo_metrica_test = rna2.evaluate(test_generator, steps=17) \n",
    "\n",
    "print(custo_metrica_train)\n",
    "print(custo_metrica_val)\n",
    "print(custo_metrica_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrM47YtmsC5k"
   },
   "source": [
    "**Saída esperada:**\n",
    "    \n",
    "    [0.38780757784843445, 0.8287878632545471]\n",
    "    [0.5447821617126465, 0.7549019455909729]\n",
    "    [0.48929181694984436, 0.7862744927406311]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xbQRmshFTYc"
   },
   "source": [
    "### Análise dos resultados\n",
    "\n",
    "Como você pode observar essa RNA treinada com \"data augmetation\" apresenta muito menos problema de \"overfitting\". Isso pode ser observado pelo seguinte:\n",
    "\n",
    "1) O comportamento da função de custo e da métrica para os dados de validação não divergem tanto em relação aos valores dos dados de treinamento, como era no caso sem \"data augmentation\".\n",
    "\n",
    "2) Os valores das métrica para os dados de validação e de teste são mais próximos dos valores obtidos para os dados de treinamento.\n",
    "\n",
    "O desempenho da RNA para as imagens de teste aumentou cerca de 5%, o que pode ser considerado um bom resultado tendo em vista que não tivemos quase nenhum trabalho para produzir novos exemplos de terinamento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IGzge70FTYe"
   },
   "source": [
    "### Teste da RNA com novas imagens\n",
    "\n",
    "Execute a célula abaixo para escolher um ou mais arquivos que estão no seu computador, carregar esses arquivos e utilizar a sua RNA com \"data augmentation\" para prever se a imagem carregada mostra um gato, ou um cão, ou um panda. Observa-se que esse código somente funciona se você estiver utilizando o Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "ItUzS_r3FTYh",
    "outputId": "3f48e43c-2891-4304-8fb8-98414dd1876b"
   },
   "outputs": [],
   "source": [
    "# Importa bibliotecas e funções\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Função do Colab para carregar arquivos\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    path = '/content/' + fn\n",
    "    # Carrega imagens usando função do Keras\n",
    "    img = image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "    # Mostra imagem\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "  \n",
    "    # Converte imagem para tensor e acrescenta eixo dos exemplos\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "  \n",
    "    # Calcula previsão da RNA e determina classe\n",
    "    y_prev = rna.predict(images, batch_size=10)\n",
    "    classe = np.argmax(y_prev)\n",
    "  \n",
    "    # Apresenta classe identificada\n",
    "    if classe==0:\n",
    "        print(fn + \" é um gato\")\n",
    "    elif classe==1:\n",
    "        print(fn + \" é um cão\")\n",
    "    else:\n",
    "        print(fn + \" é um panda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikXAm1mMwoFA"
   },
   "source": [
    "### Exercício #9: Responda a seguinte pergunta: Como melhorar o desempenho dessa rede?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkN4qqg-FTYl"
   },
   "source": [
    "## Conclusão\n",
    "\n",
    "As conclusões que podemos extrair desse trabalho são as seguintes:\n",
    "\n",
    "1) Geração artificial de dados (\"data augmentation\") é uma ferramenta poderosa para minimizar problemas de \"overfitting\". Mas obviamente tem as suas limitações, pois os novos exemplos são criados a partir dos exemplos existentes, ou seja, não se criam de fato novos exemplos.\n",
    "\n",
    "2) \"Data augmentation\" quando aplicado em conjunto com outras técnicas de regularização, tais como, regularização L2 e \"dropout\" tem a capacidade de eliminar \"overfitting\" e, assim, obter RNAs capazes de apresentar um alto desempenho, até mesmo superior ao dos seres humanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4IBgYCYooGD"
   },
   "source": [
    "## Finalizando\n",
    "\n",
    "Antes de sair do Colab ou inciar um outro notebook, execute a célula abaixo para finalizar o kernel e liberar memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "651IgjLyo-Jx"
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "T4_Gerador_dados_sol_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
