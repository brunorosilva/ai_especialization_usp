{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Byow2J6LaPl"
   },
   "source": [
    "# Aula 6\n",
    "\n",
    "# \"Data Pipelines\" - Parte 2\n",
    "\n",
    "# Etapa de treinamento\n",
    "\n",
    "### Eduardo Lobo Lustosa Cabral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALO-NQoggU4A"
   },
   "source": [
    "## 1. Objetivos\n",
    "\n",
    "Apresentar ferramentas do TensorFlow para criar \"data pipelines\" eficientes.\n",
    "\n",
    "Apresentar formas de treinar RNAs usando ferramentas de \"data pipelines\" do TensorFlow. \n",
    "\n",
    "Exemplos de treinamento de RNAs usando \"data pipelines\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7q7_sCBgU4B"
   },
   "source": [
    "### Importa principais bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OFcpn1-0gU4B"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPZeN3bkgU4C"
   },
   "source": [
    "## 2. Data Pipelines\n",
    "\n",
    "Com já vimos, existem muitos tipos de dados e problemas. Como por exemplo:\n",
    "\n",
    "-\tImagens $\\to$ classificação, detecção e localização de objetos, segmentação, geração de novas imagens.\n",
    "-\tTexto $\\to$  classificação, análise de sentimento, geração de novos textos, tradução de texto, chatbot.\n",
    "- Áudio $\\to$  reconhecimento de voz, música, geração de áudio (música e voz).\n",
    "- Vídeo $\\to$  classificação, reconhecimento de ação, rastreamento de objetos, entendimento de vídeo.\n",
    "- Séries temporais $\\to$  previsão, regressão (ajuste de função).\n",
    "- Dados estruturados $\\to$ regressão, sistemas de recomendação, classificação. \n",
    "\n",
    "<br>\n",
    "Para processar e carregar dados para treinar uma RNA de forma eficiente deve-se criar um \"data pipeline\". \n",
    "\n",
    "**Data pipelines** funcionam no princípio ETC (Extrair, Transformar e Carregar) que em inglês é ETL (Extraction, Tranformation and Load).\n",
    "\n",
    "- **Extrair** $\\to$ carrega dados originais do local onde se encontram e traz para o nosso ambiente de computação;\n",
    "- **Transformar** $\\to$ processa os dados para serem colocados em formatos adequados que possam ser usados por uma RNA;\n",
    "- **Carregar** $\\to$ alimenta a RNA com dados durante o seu treinamento ou para realizar previsões quando colocada em operação.\n",
    "\n",
    "<br>\n",
    "Cada tipo de dado exige um \"data pipeline\" diferente. Por exemplo:\n",
    "\n",
    "- Imagens $\\to$ ler arquivos, aplicar transformações em cada imagem e juntar aletoriamente em lotes para treinamento.\n",
    "-\tTexto $\\to$ ler arquivos, pode envolver extrair palavras ou letras do texto, converter em vetores “one-hote” ou “embeding” e criar lotes de sequências que podem ter comprimentos diferentes.\n",
    "-\tVídeo $\\to$ ler arquivos, separar imagens dos vídeos, aplicar transformações em cada imagem e juntar em lotes de treinamento que podem ter comprimentos diferentes.\n",
    "- Áudio e séries temporais $\\to$ ler arquivos, criar janelas com dados temporais, aplicar transformações nos dados, juntar em lotes de treinamento.\n",
    "- Dados estruturados $\\to$ ler arquivos, transformar dados e juntar em lotes para treinamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aSErreGgU4D"
   },
   "source": [
    "#### \"Data pipelines\" com TensorFlow\n",
    "\n",
    "O TensorFlow fornece ferramentas para realizar as três etapas de um \"data pipeline\" de forma eficiente para qualquer tipo de dado e problema.\n",
    "\n",
    "A grande vantagem de usar as ferramentas do TensorFlow é que elas são otimizadas para funcionar com os métodos de treinamento do Keras e, assim, o processo de treinamento é mais rápido.\n",
    "\n",
    "O módulo **`tf.data`** do TensorFlow disponibiliza ferramentas para criar \"data pipelines\" complexos de forma simples (https://www.tensorflow.org/api_docs/python/tf/data).\n",
    "\n",
    "Na Aula 4 vimos as etapas de \"extração\" e \"transformação\" dos dados **$\\to$ nessa aula veremos a etapa de carregar os dados no treinamento de uma RNA.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLRdedPpbDdD"
   },
   "source": [
    "## 3. Treinamento\n",
    "\n",
    "A última etapa de um \"data pipeline\" de dados para desenvolver uma RNA é carregar os dados durante o processo de treinamento.\n",
    "\n",
    "Com os dados em um objeto Dataset, eles são fornecidos para o treinamento da RNA de forma otimizada utilizando da melhor forma possível todos os recursos de CPU/GPU e memória disponíveis.\n",
    "\n",
    "Com um Dataset é possível utilizar os métodos `fit()`, `evaluate()` e `predict()` do Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTQe8daMcgFz"
   },
   "source": [
    "Como exemplos de usar um conjunto de dados no formato Dataset no treinamento de uma RNA, vamos mostrar dois casos:\n",
    "\n",
    "1. Dados na forma de imagens em tensores para classificação multiclasse;\n",
    "2. Dados estruturados em arquivo CSV para classificaçao binária com classes desbalanceadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaXRpL_vgU4E"
   },
   "source": [
    "## 4. Classificação  multiclasse com dados em imagens\n",
    "\n",
    "Nesse exemplos vamos utilizar os dados do conjunto Fashion-MNIST. \n",
    "\n",
    "Como já vimos o conjunto de dados Fashion-MNIST consiste de imagens de artigos de vesturário divididas em 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hv0t9KuRgU4E"
   },
   "source": [
    "### 4.1 Carregar dados\n",
    "\n",
    "O código abaixo carrega os dados da Fashion-MNIST da coleção do Keras e separa as imagens de entrada e as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-bfjqm0hOfES"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do tensor de imagens de treinamento: (60000, 28, 28)\n",
      "Dimensão do tensor de imagens de teste: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Carrega conjunto de dados do keras\n",
    "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Separa imagens e classes\n",
    "images_train, labels_train = train\n",
    "images_test, labels_test = test\n",
    "\n",
    "# Mostra dimensões dos dados\n",
    "print('Dimensão do tensor de imagens de treinamento:', images_train.shape)\n",
    "print('Dimensão do tensor de imagens de teste:', images_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWuncBcPgU4F"
   },
   "source": [
    "Pode-se ver que esse conjunto de dados possui 60.000 exemplos de treinamento e 10.000 exemplos de teste. Além disso, as imagens tem 28x28 pixels e são em tons de cinza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlR9ctOIgU4F"
   },
   "source": [
    "### 4.2 Criar Datasets de treinamento e teste\n",
    "\n",
    "Na célula abaixo são criados os Datasets de treinamento e teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2962GYZ--gVL"
   },
   "outputs": [],
   "source": [
    "# Cria datasets de treinameto e teste\n",
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "fmnist_test_ds = tf.data.Dataset.from_tensor_slices((images_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7i_guYCb-gVL"
   },
   "source": [
    "Para transformar os dados de forma a que possam ser usados por uma RNA, vamos definir a função `transform()`, que realiza as seguintes operações ao carregar os lotes de dados:\n",
    "\n",
    "1. Redefine o tipo dos dados das imagens para serem reais;\n",
    "2. Normaliza as imagens para os pixels terem valores entre 0 e 1;\n",
    "3. Codifica as classes das imagens para vetores one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8G2sZ9aUgU4F"
   },
   "outputs": [],
   "source": [
    "## Define função para normalizar as imagens codificar saída\n",
    "def transform(x, y):\n",
    "    x_norm = tf.cast(x, dtype=tf.float32)/255.\n",
    "    y_int = tf.cast(y, dtype=tf.int32)\n",
    "    y_hot = tf.one_hot(y_int, 10)\n",
    "    return x_norm, y_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gfi2dk-gU4F"
   },
   "source": [
    "- Observe que essa função recebe tanto as entradas como as saídas dos exemplos de treinamento em razão dos Datasets retornarem pares imagem-classe.\n",
    "\n",
    "Agora vamos introduzir a transformação dos dados nos Datasets de treinamento e teste criados anteriormente. Para isso usamos o método `map` e a função `transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wDhF3rGnbDdD"
   },
   "outputs": [],
   "source": [
    "# Define tamanho do lote\n",
    "batch_size = 32\n",
    "\n",
    "# Cria Dataset com a transformação que normaliza as imagens e codifica saída\n",
    "fmnist_train_ds = fmnist_train_ds.map(transform)\n",
    "fmnist_test_ds = fmnist_test_ds.map(transform)\n",
    "\n",
    "# Define tamanho de lotes e embaralha dados\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(1000).batch(batch_size)\n",
    "fmnist_test_ds = fmnist_test_ds.shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvNjH9BAgU4G"
   },
   "source": [
    "- Observe que esses Datasets retornam um lote de imagens normalizadas e saídas em vetores one-hot. Para realizar essas transfromações é usado o método `map` que chama a função `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWYDWx2UgU4G"
   },
   "source": [
    "Para verificar se os Datasets estão funcionando corretamente, vamos criar um lote e apresentar alguns exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F6z-Z-4wgU4G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe: tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do lote: (32, 28, 28)\n",
      "Valores de alguns pixels: [0.8039 0.8078 0.8    0.7922 0.7882]\n"
     ]
    }
   ],
   "source": [
    "# Gera um lote de treinamento\n",
    "img, y = next(iter(fmnist_train_ds))\n",
    "\n",
    "# Mostra primeiro exemplo do lote\n",
    "print('Classe:', y[0])\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Apresenta dimensão do lote de imagens e alguns pixels da primeira imagem\n",
    "print('Dimensão do lote:', img.shape)\n",
    "print('Valores de alguns pixels:', img[0,14,10:15].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDJrasjZgU4H"
   },
   "source": [
    "### 4.3 Configuração e compilação da RNA\n",
    "\n",
    "Como as imagens tem dimensão pequena (28x28) e são em tons de cinza, vamos usar uma RNA simples com duas camadas densas para resolver esse problema.\n",
    "\n",
    "A RNA é compilada com os seguintes parâmetros:\n",
    "\n",
    "- Método de otimização: Adam com a sua taxa de aprendizado padrão (`lr=0.001`);\n",
    "- Função de custo: `CategoricalCrossentropy`;\n",
    "- Métrica: `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "E8jpkHAMgU4H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define dimensão das imagens\n",
    "img_size = (28, 28)\n",
    "\n",
    "# Cria RNA \n",
    "rna = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=img_size),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),                    \n",
    "      tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "# Apresenta sumário da RNA\n",
    "rna.summary()\n",
    "\n",
    "# Compila RNA\n",
    "rna.compile(optimizer='adam',\n",
    "            loss= tf.keras.losses.CategoricalCrossentropy(), \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrFhoRV5gU4I"
   },
   "source": [
    "- A primeira camada da RNA é uma camada tipo `Flatten` para redimensionar as imagens e transformá-las em um vetor para poderem ser processadas por uma camada densa. Observe que o redimensionamento das imagens foi incluído dentro da RNA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdogg8CfHs-G"
   },
   "source": [
    "### 4.4 Treinamento da RNA\n",
    " \n",
    "Para treinar a RNA basta passar os Datasets de treinamento e teste da mesma forma como se estivessem em tensores.\n",
    " \n",
    "Somente para exemplificar, vamos usar poucas épocas de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9cu4kPzOHnlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 4ms/step - loss: 0.7219 - accuracy: 0.7536 - val_loss: 0.4784 - val_accuracy: 0.8302\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4201 - accuracy: 0.8530 - val_loss: 0.4513 - val_accuracy: 0.8456\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3823 - accuracy: 0.8656 - val_loss: 0.4023 - val_accuracy: 0.8593\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3606 - accuracy: 0.8713 - val_loss: 0.3968 - val_accuracy: 0.8584\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3452 - accuracy: 0.8761 - val_loss: 0.3984 - val_accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3342 - accuracy: 0.8789 - val_loss: 0.3717 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3224 - accuracy: 0.8834 - val_loss: 0.3836 - val_accuracy: 0.8617\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3157 - accuracy: 0.8851 - val_loss: 0.3712 - val_accuracy: 0.8673\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3047 - accuracy: 0.8886 - val_loss: 0.3724 - val_accuracy: 0.8664\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2964 - accuracy: 0.8914 - val_loss: 0.3833 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ca212e3c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna.fit(fmnist_train_ds, epochs=10, validation_data=fmnist_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzpAQfJMJF41"
   },
   "source": [
    "**Importante:**\n",
    "\n",
    "Como visto, um Dataset criado usando o método `repeat` gera infinitos exemplos de treinamento. Nesses casos, no treinamento deve-se usar o argumento `steps_per_epoch` para definir quantos lotes por época são desejados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTLsw_nqJpTw"
   },
   "source": [
    "### 4.5 Avaliação da RNA\n",
    "\n",
    "O método `evaluate` pode ser usado com os dados em um Dataset. \n",
    "\n",
    "Nesse caso pode-se se quiser, ou se for necessário, definir o número de lotes usados no treinamento com o argumento `steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TnlRHlaL-XUI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.8655\n",
      "Função de custo: 0.38332098722457886\n",
      "Exatidão: 0.8654999732971191\n"
     ]
    }
   ],
   "source": [
    "# Calcula função de custo e exatidão para todos os dados de teste \n",
    "loss, accuracy = rna.evaluate(fmnist_test_ds)\n",
    "\n",
    "print(\"Função de custo:\", loss)\n",
    "print(\"Exatidão:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uVgamf9HKDon"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.8906\n",
      "Função de custo: 0.26759713888168335\n",
      "Exatidão: 0.890625\n"
     ]
    }
   ],
   "source": [
    "# Calcula função de custo e exatidão para 10 lotes dos dados de teste \n",
    "loss, accuracy = rna.evaluate(fmnist_train_ds.repeat(), steps=10)\n",
    "\n",
    "print(\"Função de custo:\", loss)\n",
    "print(\"Exatidão:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZYhJ_YSIl6w"
   },
   "source": [
    "### 4.6 Realização de previsões\n",
    "\n",
    "Para usar o método `predict` para fazer previsões com a RNA as saídas não são necessárias. Assim, pode-se fazer o seguinte:\n",
    "\n",
    "1. Criar um novo Dataset com somente as imagens de teste;\n",
    "2. Usar o Dataset criado anteriormente como os dados de teste, que gera tanto as imagens como as classes, nesse caso as sáidas são ignoradas pelo método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "343lXJ-pIqWD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do tensor de previsões: (320, 10)\n",
      "Probabilidades das classes do primeiro exemplo: [8.2854e-07 2.1298e-09 6.0267e-06 1.9959e-06 6.3607e-07 6.4042e-03\n",
      " 1.8002e-07 1.5173e-01 2.3801e-04 8.4162e-01]\n"
     ]
    }
   ],
   "source": [
    "# Define função para somente normalizar imagens\n",
    "def img_norm(x):\n",
    "    x = tf.cast(x, dtype=tf.float32)/255.\n",
    "    return x\n",
    "\n",
    "# Cria novo Dataset somente com as imagens de teste sem as classes\n",
    "predict_ds = tf.data.Dataset.from_tensor_slices(images_test)\n",
    "predict_ds = predict_ds.map(img_norm).batch(batch_size)\n",
    "\n",
    "# Realiza previsões \n",
    "result = rna.predict(predict_ds, steps=10)\n",
    "                       \n",
    "# Mostra dimensão dos resultados\n",
    "print('Dimensão do tensor de previsões:', result.shape)\n",
    "print('Probabilidades das classes do primeiro exemplo:', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfzZORwLI202"
   },
   "source": [
    "- Observe que as saídas da RNA são vetores, cujos elementos representam as probabilidades da imagem ser uma das classes.\n",
    "\n",
    "Se quisermos verificar os resultados comparando com as classes reais, é mais fácil criar um lote de imagens e classes e depois usar a RNA com o método `predict` passando somente as imagens do lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8sJVFLar-gVQ"
   },
   "outputs": [],
   "source": [
    "# Gera lote de imagens e saídas reais \n",
    "img, y_real = next(iter(fmnist_test_ds))\n",
    "                        \n",
    "# Determina categoria da classe real\n",
    "classe_real = np.argmax(y_real, axis=1)\n",
    "\n",
    "# Calcula previsão da RNA para um lote de imagens\n",
    "y_prev = rna.predict(img)\n",
    "classe_prev = np.argmax(y_prev, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mgQJTPrT-2WF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe real: 6\n",
      "Classe prevista: 6\n",
      "Probabilidades das classe: [6.2678e-02 1.1513e-07 1.4786e-01 1.2641e-03 4.0749e-02 7.9797e-09\n",
      " 7.3924e-01 1.0645e-10 8.2010e-03 2.0731e-09]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAS5UlEQVR4nO3dbWyVZZoH8P9lKSLvLS8V2iIMby4aZRZsNnHcuJlIHL5UEmcDH1bW6DImaGbifIC4H8Yva8xmYULIZpLOqsOss04mwihGkoHgJC6+TKimi0VWqgR5aWkrby0g1pZrP/Rx0sE+11XPc855jnv9fwlpOVefnrun/HnOOddz37eoKojo/78b8h4AEZUHw04UBMNOFATDThQEw04UxLhy3pmI8K3/MhORXO+f3Z7yU9VRf+mZwi4i9wPYBqAKwH+o6rNZvl8lq6qqSq15gRocHCz2cMasuro6t/sGgIGBgdzu2/q9WL9PABgaGsp035X4n1zBT+NFpArAvwP4AYBlANaJyLJiDYyIiivLa/YmAB+r6jFVHQDwWwDNxRkWERVblrDXAzg54u+nktv+gohsEJFWEWnNcF9ElFGW1+yjvSD62gsVVW0B0ALwDTqiPGU5s58C0Dji7w0AOrMNh4hKJUvYDwJYLCILRGQ8gLUAdhdnWERUbAU/jVfVQRF5HMAfMNx6e15VDxdtZEWWtd+ctRVjue2228x6U1OTWX/hhRdSa3m2vjxe++vRRx816y+++KJZv3z5cmrNa4d6/168eiW23jL12VV1D4A9RRoLEZUQL5clCoJhJwqCYScKgmEnCoJhJwqCYScKoqzz2StZlr7omjVrzPratWvN+pQpU8y6N7Zz586l1q5du2YeO3fuXLN+ww32+eDKlStm/ZNPPkmt3X777eaxTz75pFlftWqVWT958mRqbevWreaxJ06cMOve41KJvn0jJqKCMOxEQTDsREEw7ERBMOxEQTDsREFIOafi5blSTdbVRB9++OHU2kMPPWQe29vba9Y/++wzsz5p0iSz/sYbb6TWXn75ZfPYjRs3mvWGhgaz/tprr5n1ffv2pda2bdtmHltXV2fWz549a9anT5+eWrv55pvNYzdt2mTWW1vtVdbGjbO72qVccThtKWme2YmCYNiJgmDYiYJg2ImCYNiJgmDYiYJg2ImCCNNnz2rnzp2pNW+aZ19fn1n3lnv2li2+6667UmteH72trc2sZ/XMM8+k1u677z7z2AMHDph179qJ8ePHp9YaGxtTawDw+eefm/UHH3zQrOeJfXai4Bh2oiAYdqIgGHaiIBh2oiAYdqIgGHaiILiU9BhZc8q9paAnTpxo1ru7u826tfUwABw6dCi1tmvXLvPYJ554wqy//vrrZn3PHnsTX+uxsa5dAIDq6mqzPnPmTLNeX1+fWvOW2J46dapZnzVrlln31jDIQ6awi8hxAP0AhgAMqurKYgyKiIqvGGf2v1NVe6kVIsodX7MTBZE17Apgr4i8JyIbRvsCEdkgIq0iYi/aRUQllfVp/N2q2ikiswHsE5H/VdU3R36BqrYAaAG+3RNhiL7tMp3ZVbUz+dgD4PcAmooxKCIqvoLDLiKTRGTKV58DWAWgvVgDI6LiKng+u4h8B8Nnc2D45cB/qeq/OMdU7NP4pib7ScmWLVtSa97c5wkTJph17/gzZ84U/P2/+OIL89iFCxea9draWrPe2dlp1q0tm72xeb1u73GdN29eas3a5hrw+/Dbt28363v37jXrpZQ2n73g1+yqegzAnQWPiIjKiq03oiAYdqIgGHaiIBh2oiAYdqIgOMU10dzcbNatNpG3/a43xfWWW24x6/39/Wb96NGjqbWrV69m+t5ffvmlWfd+dqutaG2pDAA33GCfi7y24OTJk1NrXV1d5rGeFStWmPU8W29peGYnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJ99sTy5cvN+sWLF1NrXp/c6wd7veyOjg6zbi1zXVNTYx576dIls+6NzbpvwN42+fz58+axnsWLF5v1G2+8MbXmLVPtLd+9dOlSs16JeGYnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJ99oS3Ba+1ZLI1bxrwtxY+duyYWffmfc+ZMye15i3XXFVVZda9JZW9n+3ChQupNW8p6BkzZph1q48O2NtFe8d61wB4x1cintmJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmCfPeHNb7bmZXtzur0tl73jGxoazLq1LbLH6+EPDQ2Z9e7u7oKPt/rggP2YA3YPHwAWLFiQWvOujfDu26tXIvfMLiLPi0iPiLSPuK1WRPaJSEfy0V4hgYhyN5an8b8CcP91t20GsF9VFwPYn/ydiCqYG3ZVfRPAuetubgawI/l8B4AHijwuIiqyQl+z16lqFwCoapeIzE77QhHZAGBDgfdDREVS8jfoVLUFQAsAiIiW+v6IaHSFtt66RWQOACQfe4o3JCIqhULDvhvA+uTz9QBeLc5wiKhU3KfxIvISgHsBzBSRUwB+BuBZAL8TkUcAnADww1IOshysfcQBe69wr2f7yiuvmPV77rnHrKvar37a29tTa3feead5rLcuvLe/u3cNwP79+1Nrs2envtUDwJ9Lf9NNN5l1a8651+P3rn2w1hCoVG7YVXVdSun7RR4LEZUQL5clCoJhJwqCYScKgmEnCoJhJwqCU1wTImLWrdabt6ywty2y9b0Bf/qt1SaaN2+eeaw3TXRwcNCse0tVT5w4MbXmLUNtbZMN+I/LRx99lFqbNm2aeay3xLb1c1UqntmJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmCfPeH12b2+rMXrF9fU2IvzHj161KyPG5f+a7xy5Yp5rDeV0+NNgbX61d5j7vW6Fy1aZNYfe+yx1Nr27dvNY70psN61FbW1tWb93Lnrl3UsPZ7ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYII02f3+qbeksrWksleH/3TTz8t+HsDwOHDh8261a/2tlSuq6sz697jdvr0abNuzfv2luD2trr2tpMeGBhIrdXX15vHXr582ayfOHHCrHvrCLDPTkQlw7ATBcGwEwXBsBMFwbATBcGwEwXBsBMFEabPPnfuXLPubQ88fvz41Fp/f7957PTp082616f3euXWvG9v3Xev1+1tZW3NpQfsx8bbitqbK+89bt7vxeJtB+09rt6Wzm1tbd94TFm5Z3YReV5EekSkfcRtT4vIaRFpS/6sLu0wiSirsTyN/xWA+0e5/eequjz5s6e4wyKiYnPDrqpvAij/tX1EVFRZ3qB7XEQOJU/zUxdRE5ENItIqIq0Z7ouIMio07L8AsBDAcgBdALakfaGqtqjqSlVdWeB9EVERFBR2Ve1W1SFVvQbglwCaijssIiq2gsIuIiP7CmsAtKd9LRFVBrfPLiIvAbgXwEwROQXgZwDuFZHlABTAcQA/KuEYi2L+/Plm3dsj3dqH3JvzvXKl/Qrm7NmzZr2vr8+sW71w7+fyeH14b2xWr3vChAmZ7tubc26t9e/18L3rBzze3vN5cH8iVV03ys3PlWAsRFRCvFyWKAiGnSgIhp0oCIadKAiGnSiIMFNcrSWNAX+Kq9XC8rZF9tp+XgvJ2x7Ymo7pbTXtLaFttRwBoLq62qxbY/d+Lu++vbbfkiVLUmveUs7eVtbe1F9vimseeGYnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCiJMn91bztmb8mgt1+z1qr26tyxxbW2tWfeWmrZMnTrVrHu98FOnTpl1awlubxqpt5yztxX2HXfckVrzrqvwxub14WfPnm3W88AzO1EQDDtREAw7URAMO1EQDDtREAw7URAMO1EQYfrs3pbNAwMDZt1a9tibd33hwgWzbvXwAf8agbq6utSa1ecG/HnX3nz1jo4Os24tB+0tJe0t0d3b22vWly1bllrz+uhDQ0Nm3evTe/U88MxOFATDThQEw04UBMNOFATDThQEw04UBMNOFESYPntjY6NZ9/quVt/U67N789m9OePeGufW2Lw16737/vDDD826N6/b6pV7j7m37bG3drt1fYO3hoCImHXPokWLMh1fCu6ZXUQaReSPInJERA6LyI+T22tFZJ+IdCQfa0o/XCIq1Fiexg8C+Kmq/hWAvwGwUUSWAdgMYL+qLgawP/k7EVUoN+yq2qWq7yef9wM4AqAeQDOAHcmX7QDwQKkGSUTZfaPX7CIyH8B3AfwJQJ2qdgHD/yGIyKiLbonIBgAbsg2TiLIac9hFZDKAnQB+oqp9Y30DQ1VbALQk30MLGSQRZTem1puIVGM46L9R1V3Jzd0iMiepzwHQU5ohElExuGd2GT6FPwfgiKpuHVHaDWA9gGeTj6+WZIRF4k2X9FpI1pbN3vRZb8ljbxqpNU0UsJdcvnTpknms177yxuZNBbWmDmddztm7b2t6r7fNttf286bnetOS8zCWp/F3A/gHAB+ISFty21MYDvnvROQRACcA/LA0QySiYnDDrqoHAKS9QP9+cYdDRKXCy2WJgmDYiYJg2ImCYNiJgmDYiYIIM8XV69l6/WarX+z18L3v7bF6/ADQ05N+PdOsWbPMY72xedNzvWWwp02bVvCxfX19Zv3ixYtmvb6+PrXmbYPt6e/vN+udnZ2Zvn8p8MxOFATDThQEw04UBMNOFATDThQEw04UBMNOFESYPrs3/9jru1pzo73tns+fP2/WvbnP3nx4a164N5/dWwb77NmzZt1botuaa+8t5+xdX+BtR23NWfdWWpo4caJZ966t8JbozgPP7ERBMOxEQTDsREEw7ERBMOxEQTDsREEw7ERBhOmze/O2vb6o1cu+fPmyeWxDQ4NZ9+ZGW/PVAXtet9cn9+aEe+sAeNcnWP3o9vZ281jv+gSvD2/9Xrx1473fibfPgDf2PPDMThQEw04UBMNOFATDThQEw04UBMNOFATDThTEWPZnbwTwawA3A7gGoEVVt4nI0wD+CUBv8qVPqeqeUg00K2/+8aJFiwr+3u+++65Zt9ZOH4vVq1ebdatn7PWivcdFVc361atXzbo1Z917XLy5+N6cdGtvee/aCG+9/aVLl5r1t956y6znYSwX1QwC+Kmqvi8iUwC8JyL7ktrPVfXfSjc8IiqWsezP3gWgK/m8X0SOAEjfaoOIKtI3es0uIvMBfBfAn5KbHheRQyLyvIjUpByzQURaRaQ100iJKJMxh11EJgPYCeAnqtoH4BcAFgJYjuEz/5bRjlPVFlVdqaorizBeIirQmMIuItUYDvpvVHUXAKhqt6oOqeo1AL8E0FS6YRJRVm7YZfgtz+cAHFHVrSNunzPiy9YAsKcwEVGuxGutiMj3APw3gA8w3HoDgKcArMPwU3gFcBzAj5I386zvZd9ZCdXUjPqWwp+tWLHCrL/99tuptU2bNpnHNjc3m/WDBw+adW+6ZW9vb2rN+/16SyZ7S017U2StZbK9tp9X96aZ3nrrram1d955xzx28+bNZn3JkiVm/dChQ2a9lFR11J7kWN6NPwBgtIMrtqdORF/HK+iIgmDYiYJg2ImCYNiJgmDYiYJg2ImCcPvsRb2zHPvsefKmQ3pbNnu97pkzZ6bWZsyYYR7rbWXt9dGrqqrMujWV1Pu5vOsLzpw5Y9atKbAnT540j/02S+uz88xOFATDThQEw04UBMNOFATDThQEw04UBMNOFES5++y9AD4dcdNMAJ+VbQDfTKWOrVLHBXBshSrm2G5R1VHXwS5r2L925yKtlbo2XaWOrVLHBXBshSrX2Pg0nigIhp0oiLzD3pLz/VsqdWyVOi6AYytUWcaW62t2IiqfvM/sRFQmDDtRELmEXUTuF5GPRORjEbEX6C4zETkuIh+ISFve+9Mle+j1iEj7iNtqRWSfiHQkH+0F8cs7tqdF5HTy2LWJiL3XdOnG1igifxSRIyJyWER+nNye62NnjKssj1vZX7OLSBWAowDuA3AKwEEA61T1w7IOJIWIHAewUlVzvwBDRP4WwCUAv1bV25Pb/hXAOVV9NvmPskZV7V0qyje2pwFcynsb72S3ojkjtxkH8ACAf0SOj50xrr9HGR63PM7sTQA+VtVjqjoA4LcA7C1TglLVNwGcu+7mZgA7ks93YPgfS9mljK0iqGqXqr6ffN4P4KttxnN97IxxlUUeYa8HMHJNoFOorP3eFcBeEXlPRDbkPZhR1H21zVbycXbO47meu413OV23zXjFPHaFbH+eVR5hH219rErq/92tqn8N4AcANiZPV2lsxrSNd7mMss14RSh0+/Os8gj7KQCNI/7eAKAzh3GMSlU7k489AH6PytuKuvurHXSTjz05j+fPKmkb79G2GUcFPHZ5bn+eR9gPAlgsIgtEZDyAtQB25zCOrxGRSckbJxCRSQBWofK2ot4NYH3y+XoAr+Y4lr9QKdt4p20zjpwfu9y3P1fVsv8BsBrD78h/AuCf8xhDyri+A+B/kj+H8x4bgJcw/LTuSww/I3oEwAwA+wF0JB9rK2hs/4nhrb0PYThYc3Ia2/cw/NLwEIC25M/qvB87Y1xledx4uSxRELyCjigIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiI/wNfpShfBVsclAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seleciona exemplo para mostrar resultado\n",
    "index = 31\n",
    "\n",
    "# Mostra um exemplo do lote\n",
    "print('Classe real:', classe_real[index])\n",
    "print('Classe prevista:', classe_prev[index])\n",
    "print('Probabilidades das classe:' , y_prev[index])\n",
    "plt.imshow(img[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8sK_z_ngU4M"
   },
   "source": [
    "## 5.  Classificação binária com classes desbalanceadas - dados estruturados\n",
    "\n",
    "Nesse exemplo vamos utilizar os dados do conjunto \"The credit card fraud\".\n",
    "\n",
    "Como já vimos na aula passada, esse conjunto de dados consiste de um problema de classificação binária com dados desbalanceados, onde os dados sem fraude (classe = 0) representam 99,6% do total e os dados com fraude (classe=1) representam 0,4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKmtvukMgU4M"
   },
   "source": [
    "### 5.1 Carregar os dados\n",
    "\n",
    "Vamos carregar os dados para podermos visualizá-los diretamente do arquivo onde se encontram.\n",
    "\n",
    "Nas céulas abaixo é definido o local onde se encontra os dados e depois os dados são carregados e descompactados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "CSse_O_6gU4N",
    "outputId": "9d7a4c33-ec59-40ef-f843-6ee7827ea260"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284802</td>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284803</td>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284804</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284805</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284806</td>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcZMXBBYgU4N"
   },
   "source": [
    "#### Características dos dados:\n",
    "\n",
    "- Existem 284.807 exemplos de treinamento (cada linha é um exemplo);\n",
    "- Cada exemplo é composto por um vetor de entrada com 30 características e uma saída;\n",
    "- As 30 características são as primeiras 30 colunas dos dados;\n",
    "- As saídas estão na última coluna, de nome \"Class\".\n",
    "\n",
    "Vamos verificar os tipos de dados de cada coluna. Isso é importante porque se existir algum dado na forma de string ele tem que ser transformado para real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqMtaJSBgU4N",
    "outputId": "be07f79e-60cc-4cd1-f44d-7c30f0dfbf3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKEAtKhvgU4N"
   },
   "source": [
    "Vamos calcular a estatísticas das colunas para verificar como devemos pré-processar cada elemento dos exemplos de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "hAVCXTpIgU4O",
    "outputId": "a64740a9-d0c9-465e-e5f7-5f407bceee6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwjTdMuJgU4O"
   },
   "source": [
    "### 5.2 Pré-processamento dos dados\n",
    "\n",
    "Para pré-processador os dados temos que fazer uma análise cuidadosa de cada característica (coluna) individualmente. Contudo, vamos realizar uma análise bastante simplificada, pois analisar dados não é o objetivo dessa aula.\n",
    "\n",
    "Analisando cada uma das colunas de características temos que:\n",
    "\n",
    "1. A primeira coluna, de nome \"Time\", não parece ter nenhuma informação relevante, assim, podemos tirá-la dos dados;\n",
    "\n",
    "\n",
    "2. As colunas de nomes \"V1\" a \"V28\" são valores reais que variam de negativo a positivo e todas possuem média praticamente igual a 0 e desvio padrão igual a 1. Então vamos deixá-las como estão mesmo que alguns valores sejam da ordem de $10^1$.\n",
    "\n",
    "\n",
    "3. A coluna \"Amount\" possui somente valores positivos, então podemos simplesmente dividi-la pelo seu valor máximo ou pelo seu desvio padrão.\n",
    "\n",
    "Podemos realizar o pré-processamento dos dados previamente, ou podemos realizar esse processsamento ao obter os lotes de dados durante o treinamento $\\to$ nesse exemplo vamos realizar o pré-processamento com o Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVozDnfSgU4O"
   },
   "source": [
    "#### Embaralhamento aleatório dos dados\n",
    "\n",
    "Para evitar qualquer tendência existente nos dados vamos embaralhá-los aleatóriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "CN5RZwc7gU4O",
    "outputId": "11936b6f-f304-4099-b7a2-d92444d0239f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>85129</td>\n",
       "      <td>60619.0</td>\n",
       "      <td>-4.263879</td>\n",
       "      <td>1.531533</td>\n",
       "      <td>-0.881850</td>\n",
       "      <td>0.369056</td>\n",
       "      <td>-0.514140</td>\n",
       "      <td>-1.594743</td>\n",
       "      <td>-0.101346</td>\n",
       "      <td>1.193836</td>\n",
       "      <td>-0.849638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108703</td>\n",
       "      <td>-0.079921</td>\n",
       "      <td>-1.095747</td>\n",
       "      <td>0.480455</td>\n",
       "      <td>0.808549</td>\n",
       "      <td>-0.496222</td>\n",
       "      <td>-1.095475</td>\n",
       "      <td>-0.877064</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252207</td>\n",
       "      <td>155697.0</td>\n",
       "      <td>1.969242</td>\n",
       "      <td>0.678002</td>\n",
       "      <td>-1.014505</td>\n",
       "      <td>3.566441</td>\n",
       "      <td>0.837346</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.326780</td>\n",
       "      <td>-0.163696</td>\n",
       "      <td>-1.227127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>0.626940</td>\n",
       "      <td>0.062197</td>\n",
       "      <td>0.581720</td>\n",
       "      <td>0.192720</td>\n",
       "      <td>0.106373</td>\n",
       "      <td>-0.047759</td>\n",
       "      <td>-0.045136</td>\n",
       "      <td>7.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115023</td>\n",
       "      <td>73720.0</td>\n",
       "      <td>-1.369214</td>\n",
       "      <td>1.433765</td>\n",
       "      <td>1.251207</td>\n",
       "      <td>-0.486622</td>\n",
       "      <td>0.260683</td>\n",
       "      <td>0.321789</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>0.210786</td>\n",
       "      <td>0.333815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301539</td>\n",
       "      <td>-0.359479</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-0.337050</td>\n",
       "      <td>-0.208764</td>\n",
       "      <td>0.104767</td>\n",
       "      <td>0.541115</td>\n",
       "      <td>0.149693</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51618</td>\n",
       "      <td>45040.0</td>\n",
       "      <td>-0.844695</td>\n",
       "      <td>1.118401</td>\n",
       "      <td>1.017805</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>-0.550155</td>\n",
       "      <td>0.537968</td>\n",
       "      <td>0.072987</td>\n",
       "      <td>-0.334224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272191</td>\n",
       "      <td>-0.658426</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>-0.081114</td>\n",
       "      <td>0.074103</td>\n",
       "      <td>0.244079</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261545</td>\n",
       "      <td>160067.0</td>\n",
       "      <td>1.993847</td>\n",
       "      <td>-0.055200</td>\n",
       "      <td>-0.419167</td>\n",
       "      <td>1.162541</td>\n",
       "      <td>-0.156547</td>\n",
       "      <td>-0.006745</td>\n",
       "      <td>-0.477176</td>\n",
       "      <td>-0.008400</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212646</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.142122</td>\n",
       "      <td>0.584253</td>\n",
       "      <td>-0.009863</td>\n",
       "      <td>-0.587657</td>\n",
       "      <td>0.058732</td>\n",
       "      <td>-0.023721</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>939.0</td>\n",
       "      <td>-0.334479</td>\n",
       "      <td>0.226390</td>\n",
       "      <td>1.970052</td>\n",
       "      <td>1.813235</td>\n",
       "      <td>-0.308007</td>\n",
       "      <td>-0.046253</td>\n",
       "      <td>0.126702</td>\n",
       "      <td>-0.203989</td>\n",
       "      <td>0.316727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.900969</td>\n",
       "      <td>-0.210252</td>\n",
       "      <td>0.460403</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>-0.091483</td>\n",
       "      <td>-0.050375</td>\n",
       "      <td>-0.150339</td>\n",
       "      <td>64.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32063</td>\n",
       "      <td>36623.0</td>\n",
       "      <td>1.323817</td>\n",
       "      <td>-0.859510</td>\n",
       "      <td>1.198582</td>\n",
       "      <td>-0.346080</td>\n",
       "      <td>-1.783544</td>\n",
       "      <td>-0.399575</td>\n",
       "      <td>-1.168795</td>\n",
       "      <td>0.093311</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491773</td>\n",
       "      <td>-0.805212</td>\n",
       "      <td>0.156814</td>\n",
       "      <td>0.398901</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39650</td>\n",
       "      <td>39913.0</td>\n",
       "      <td>-1.356966</td>\n",
       "      <td>-4.949006</td>\n",
       "      <td>-0.577724</td>\n",
       "      <td>-0.226900</td>\n",
       "      <td>-2.865498</td>\n",
       "      <td>-0.277220</td>\n",
       "      <td>0.872936</td>\n",
       "      <td>-0.162877</td>\n",
       "      <td>1.795679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963005</td>\n",
       "      <td>-0.109074</td>\n",
       "      <td>-1.241825</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>-0.123270</td>\n",
       "      <td>-0.051770</td>\n",
       "      <td>-0.221688</td>\n",
       "      <td>0.242943</td>\n",
       "      <td>1334.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142035</td>\n",
       "      <td>84556.0</td>\n",
       "      <td>-1.193074</td>\n",
       "      <td>1.788381</td>\n",
       "      <td>1.263928</td>\n",
       "      <td>2.175369</td>\n",
       "      <td>-0.444923</td>\n",
       "      <td>-0.075733</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.802215</td>\n",
       "      <td>-1.274251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117001</td>\n",
       "      <td>0.243881</td>\n",
       "      <td>-0.146728</td>\n",
       "      <td>0.424643</td>\n",
       "      <td>0.242298</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>-0.313478</td>\n",
       "      <td>-0.065787</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28740</td>\n",
       "      <td>35135.0</td>\n",
       "      <td>-0.563180</td>\n",
       "      <td>1.131079</td>\n",
       "      <td>1.240222</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.317145</td>\n",
       "      <td>-0.511428</td>\n",
       "      <td>0.680701</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>-0.463070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213678</td>\n",
       "      <td>-0.494878</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>0.045508</td>\n",
       "      <td>-0.197608</td>\n",
       "      <td>0.088561</td>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "85129    60619.0 -4.263879  1.531533 -0.881850  0.369056 -0.514140 -1.594743   \n",
       "252207  155697.0  1.969242  0.678002 -1.014505  3.566441  0.837346  0.035869   \n",
       "115023   73720.0 -1.369214  1.433765  1.251207 -0.486622  0.260683  0.321789   \n",
       "51618    45040.0 -0.844695  1.118401  1.017805 -0.155149  0.267244 -0.550155   \n",
       "261545  160067.0  1.993847 -0.055200 -0.419167  1.162541 -0.156547 -0.006745   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1214       939.0 -0.334479  0.226390  1.970052  1.813235 -0.308007 -0.046253   \n",
       "32063    36623.0  1.323817 -0.859510  1.198582 -0.346080 -1.783544 -0.399575   \n",
       "39650    39913.0 -1.356966 -4.949006 -0.577724 -0.226900 -2.865498 -0.277220   \n",
       "142035   84556.0 -1.193074  1.788381  1.263928  2.175369 -0.444923 -0.075733   \n",
       "28740    35135.0 -0.563180  1.131079  1.240222  0.006803  0.317145 -0.511428   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "85129  -0.101346  1.193836 -0.849638  ...  0.108703 -0.079921 -1.095747   \n",
       "252207  0.326780 -0.163696 -1.227127  ...  0.218127  0.626940  0.062197   \n",
       "115023  0.582015  0.210786  0.333815  ... -0.301539 -0.359479  0.041979   \n",
       "51618   0.537968  0.072987 -0.334224  ... -0.272191 -0.658426  0.062159   \n",
       "261545 -0.477176 -0.008400  0.769874  ...  0.212646  0.789730  0.142122   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "1214    0.126702 -0.203989  0.316727  ...  0.146153  0.900969 -0.210252   \n",
       "32063  -1.168795  0.093311  0.122400  ... -0.491773 -0.805212  0.156814   \n",
       "39650   0.872936 -0.162877  1.795679  ...  0.963005 -0.109074 -1.241825   \n",
       "142035  0.003887  0.802215 -1.274251  ...  0.117001  0.243881 -0.146728   \n",
       "28740   0.680701 -0.023212 -0.463070  ... -0.213678 -0.494878  0.077872   \n",
       "\n",
       "             V24       V25       V26       V27       V28   Amount  Class  \n",
       "85129   0.480455  0.808549 -0.496222 -1.095475 -0.877064     2.69      0  \n",
       "252207  0.581720  0.192720  0.106373 -0.047759 -0.045136     7.53      0  \n",
       "115023 -0.337050 -0.208764  0.104767  0.541115  0.149693     8.98      0  \n",
       "51618  -0.056504 -0.081114  0.074103  0.244079  0.128198     4.49      0  \n",
       "261545  0.584253 -0.009863 -0.587657  0.058732 -0.023721     1.00      0  \n",
       "...          ...       ...       ...       ...       ...      ...    ...  \n",
       "1214    0.460403 -0.305401 -0.091483 -0.050375 -0.150339    64.50      0  \n",
       "32063   0.398901 -0.028284  0.963086 -0.012312  0.019683     7.55      0  \n",
       "39650   0.639999 -0.123270 -0.051770 -0.221688  0.242943  1334.00      0  \n",
       "142035  0.424643  0.242298  0.023849 -0.313478 -0.065787    11.35      0  \n",
       "28740   0.045508 -0.197608  0.088561  0.142364  0.086743     4.99      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled=df.sample(frac=1)\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y348_AbBgU4O"
   },
   "source": [
    "#### Separar as saídas desejadas\n",
    "\n",
    "Se vamos criar um Dataset a partir de um DataFrame Pandas devemos separar as entradas das saídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKlc8P-cgU4O",
    "outputId": "48a5664b-a978-4f3b-896e-7b12250efa2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85129     0\n",
       "252207    0\n",
       "115023    0\n",
       "51618     0\n",
       "261545    0\n",
       "         ..\n",
       "1214      0\n",
       "32063     0\n",
       "39650     0\n",
       "142035    0\n",
       "28740     0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separa o vetor de saídas desejadas\n",
    "y = df_shuffled.Class\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf9mvgDegU4P"
   },
   "source": [
    "#### Remover as colunas desnecessárias\n",
    "\n",
    "Tendo o vetor de saídas desejadas, agora devemos remover as colunas \"Time\", que não tem informação nenhuma, e a coluna das saídas (\"Class\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "xpnra0sygU4P",
    "outputId": "df195e4f-aa86-4914-fe73-08212c3607ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>85129</td>\n",
       "      <td>-4.263879</td>\n",
       "      <td>1.531533</td>\n",
       "      <td>-0.881850</td>\n",
       "      <td>0.369056</td>\n",
       "      <td>-0.514140</td>\n",
       "      <td>-1.594743</td>\n",
       "      <td>-0.101346</td>\n",
       "      <td>1.193836</td>\n",
       "      <td>-0.849638</td>\n",
       "      <td>-0.380547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446457</td>\n",
       "      <td>0.108703</td>\n",
       "      <td>-0.079921</td>\n",
       "      <td>-1.095747</td>\n",
       "      <td>0.480455</td>\n",
       "      <td>0.808549</td>\n",
       "      <td>-0.496222</td>\n",
       "      <td>-1.095475</td>\n",
       "      <td>-0.877064</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252207</td>\n",
       "      <td>1.969242</td>\n",
       "      <td>0.678002</td>\n",
       "      <td>-1.014505</td>\n",
       "      <td>3.566441</td>\n",
       "      <td>0.837346</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.326780</td>\n",
       "      <td>-0.163696</td>\n",
       "      <td>-1.227127</td>\n",
       "      <td>1.522018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207333</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>0.626940</td>\n",
       "      <td>0.062197</td>\n",
       "      <td>0.581720</td>\n",
       "      <td>0.192720</td>\n",
       "      <td>0.106373</td>\n",
       "      <td>-0.047759</td>\n",
       "      <td>-0.045136</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115023</td>\n",
       "      <td>-1.369214</td>\n",
       "      <td>1.433765</td>\n",
       "      <td>1.251207</td>\n",
       "      <td>-0.486622</td>\n",
       "      <td>0.260683</td>\n",
       "      <td>0.321789</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>0.210786</td>\n",
       "      <td>0.333815</td>\n",
       "      <td>1.228397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585544</td>\n",
       "      <td>-0.301539</td>\n",
       "      <td>-0.359479</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-0.337050</td>\n",
       "      <td>-0.208764</td>\n",
       "      <td>0.104767</td>\n",
       "      <td>0.541115</td>\n",
       "      <td>0.149693</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51618</td>\n",
       "      <td>-0.844695</td>\n",
       "      <td>1.118401</td>\n",
       "      <td>1.017805</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>-0.550155</td>\n",
       "      <td>0.537968</td>\n",
       "      <td>0.072987</td>\n",
       "      <td>-0.334224</td>\n",
       "      <td>0.093294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176013</td>\n",
       "      <td>-0.272191</td>\n",
       "      <td>-0.658426</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>-0.056504</td>\n",
       "      <td>-0.081114</td>\n",
       "      <td>0.074103</td>\n",
       "      <td>0.244079</td>\n",
       "      <td>0.128198</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261545</td>\n",
       "      <td>1.993847</td>\n",
       "      <td>-0.055200</td>\n",
       "      <td>-0.419167</td>\n",
       "      <td>1.162541</td>\n",
       "      <td>-0.156547</td>\n",
       "      <td>-0.006745</td>\n",
       "      <td>-0.477176</td>\n",
       "      <td>-0.008400</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.193681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165150</td>\n",
       "      <td>0.212646</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.142122</td>\n",
       "      <td>0.584253</td>\n",
       "      <td>-0.009863</td>\n",
       "      <td>-0.587657</td>\n",
       "      <td>0.058732</td>\n",
       "      <td>-0.023721</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>-0.334479</td>\n",
       "      <td>0.226390</td>\n",
       "      <td>1.970052</td>\n",
       "      <td>1.813235</td>\n",
       "      <td>-0.308007</td>\n",
       "      <td>-0.046253</td>\n",
       "      <td>0.126702</td>\n",
       "      <td>-0.203989</td>\n",
       "      <td>0.316727</td>\n",
       "      <td>0.242608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133574</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.900969</td>\n",
       "      <td>-0.210252</td>\n",
       "      <td>0.460403</td>\n",
       "      <td>-0.305401</td>\n",
       "      <td>-0.091483</td>\n",
       "      <td>-0.050375</td>\n",
       "      <td>-0.150339</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32063</td>\n",
       "      <td>1.323817</td>\n",
       "      <td>-0.859510</td>\n",
       "      <td>1.198582</td>\n",
       "      <td>-0.346080</td>\n",
       "      <td>-1.783544</td>\n",
       "      <td>-0.399575</td>\n",
       "      <td>-1.168795</td>\n",
       "      <td>0.093311</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.513097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.541264</td>\n",
       "      <td>-0.491773</td>\n",
       "      <td>-0.805212</td>\n",
       "      <td>0.156814</td>\n",
       "      <td>0.398901</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>0.963086</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39650</td>\n",
       "      <td>-1.356966</td>\n",
       "      <td>-4.949006</td>\n",
       "      <td>-0.577724</td>\n",
       "      <td>-0.226900</td>\n",
       "      <td>-2.865498</td>\n",
       "      <td>-0.277220</td>\n",
       "      <td>0.872936</td>\n",
       "      <td>-0.162877</td>\n",
       "      <td>1.795679</td>\n",
       "      <td>-1.554730</td>\n",
       "      <td>...</td>\n",
       "      <td>2.511559</td>\n",
       "      <td>0.963005</td>\n",
       "      <td>-0.109074</td>\n",
       "      <td>-1.241825</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>-0.123270</td>\n",
       "      <td>-0.051770</td>\n",
       "      <td>-0.221688</td>\n",
       "      <td>0.242943</td>\n",
       "      <td>1334.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142035</td>\n",
       "      <td>-1.193074</td>\n",
       "      <td>1.788381</td>\n",
       "      <td>1.263928</td>\n",
       "      <td>2.175369</td>\n",
       "      <td>-0.444923</td>\n",
       "      <td>-0.075733</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.802215</td>\n",
       "      <td>-1.274251</td>\n",
       "      <td>-0.314212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262530</td>\n",
       "      <td>0.117001</td>\n",
       "      <td>0.243881</td>\n",
       "      <td>-0.146728</td>\n",
       "      <td>0.424643</td>\n",
       "      <td>0.242298</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>-0.313478</td>\n",
       "      <td>-0.065787</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28740</td>\n",
       "      <td>-0.563180</td>\n",
       "      <td>1.131079</td>\n",
       "      <td>1.240222</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.317145</td>\n",
       "      <td>-0.511428</td>\n",
       "      <td>0.680701</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>-0.463070</td>\n",
       "      <td>-0.470285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113191</td>\n",
       "      <td>-0.213678</td>\n",
       "      <td>-0.494878</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>0.045508</td>\n",
       "      <td>-0.197608</td>\n",
       "      <td>0.088561</td>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "85129  -4.263879  1.531533 -0.881850  0.369056 -0.514140 -1.594743 -0.101346   \n",
       "252207  1.969242  0.678002 -1.014505  3.566441  0.837346  0.035869  0.326780   \n",
       "115023 -1.369214  1.433765  1.251207 -0.486622  0.260683  0.321789  0.582015   \n",
       "51618  -0.844695  1.118401  1.017805 -0.155149  0.267244 -0.550155  0.537968   \n",
       "261545  1.993847 -0.055200 -0.419167  1.162541 -0.156547 -0.006745 -0.477176   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1214   -0.334479  0.226390  1.970052  1.813235 -0.308007 -0.046253  0.126702   \n",
       "32063   1.323817 -0.859510  1.198582 -0.346080 -1.783544 -0.399575 -1.168795   \n",
       "39650  -1.356966 -4.949006 -0.577724 -0.226900 -2.865498 -0.277220  0.872936   \n",
       "142035 -1.193074  1.788381  1.263928  2.175369 -0.444923 -0.075733  0.003887   \n",
       "28740  -0.563180  1.131079  1.240222  0.006803  0.317145 -0.511428  0.680701   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "85129   1.193836 -0.849638 -0.380547  ... -0.446457  0.108703 -0.079921   \n",
       "252207 -0.163696 -1.227127  1.522018  ... -0.207333  0.218127  0.626940   \n",
       "115023  0.210786  0.333815  1.228397  ...  0.585544 -0.301539 -0.359479   \n",
       "51618   0.072987 -0.334224  0.093294  ...  0.176013 -0.272191 -0.658426   \n",
       "261545 -0.008400  0.769874  0.193681  ... -0.165150  0.212646  0.789730   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "1214   -0.203989  0.316727  0.242608  ...  0.133574  0.146153  0.900969   \n",
       "32063   0.093311  0.122400  0.513097  ... -0.541264 -0.491773 -0.805212   \n",
       "39650  -0.162877  1.795679 -1.554730  ...  2.511559  0.963005 -0.109074   \n",
       "142035  0.802215 -1.274251 -0.314212  ... -0.262530  0.117001  0.243881   \n",
       "28740  -0.023212 -0.463070 -0.470285  ...  0.113191 -0.213678 -0.494878   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28   Amount  \n",
       "85129  -1.095747  0.480455  0.808549 -0.496222 -1.095475 -0.877064     2.69  \n",
       "252207  0.062197  0.581720  0.192720  0.106373 -0.047759 -0.045136     7.53  \n",
       "115023  0.041979 -0.337050 -0.208764  0.104767  0.541115  0.149693     8.98  \n",
       "51618   0.062159 -0.056504 -0.081114  0.074103  0.244079  0.128198     4.49  \n",
       "261545  0.142122  0.584253 -0.009863 -0.587657  0.058732 -0.023721     1.00  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "1214   -0.210252  0.460403 -0.305401 -0.091483 -0.050375 -0.150339    64.50  \n",
       "32063   0.156814  0.398901 -0.028284  0.963086 -0.012312  0.019683     7.55  \n",
       "39650  -1.241825  0.639999 -0.123270 -0.051770 -0.221688  0.242943  1334.00  \n",
       "142035 -0.146728  0.424643  0.242298  0.023849 -0.313478 -0.065787    11.35  \n",
       "28740   0.077872  0.045508 -0.197608  0.088561  0.142364  0.086743     4.99  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remoção da coluna \"Time\" e da saída \n",
    "df_shuffled.drop(['Time', 'Class'], axis=1, inplace=True)\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZmQ_TLGgU4P"
   },
   "source": [
    "#### Normalizar a coluna \"Amount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "6kL6MFyLgU4P",
    "outputId": "41cb5692-d6f4-4e90-dd0a-24ec99df3ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.171056e-15</td>\n",
       "      <td>3.044930e-16</td>\n",
       "      <td>-1.412964e-15</td>\n",
       "      <td>2.100790e-15</td>\n",
       "      <td>9.964609e-16</td>\n",
       "      <td>1.495077e-15</td>\n",
       "      <td>-6.116418e-16</td>\n",
       "      <td>1.279507e-16</td>\n",
       "      <td>-2.435559e-15</td>\n",
       "      <td>2.229535e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>6.458078e-16</td>\n",
       "      <td>1.524623e-16</td>\n",
       "      <td>-3.402380e-16</td>\n",
       "      <td>2.593103e-16</td>\n",
       "      <td>4.468456e-15</td>\n",
       "      <td>5.280639e-16</td>\n",
       "      <td>1.669484e-15</td>\n",
       "      <td>-3.610374e-16</td>\n",
       "      <td>-1.212174e-16</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>0.009736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>0.000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.171056e-15  3.044930e-16 -1.412964e-15  2.100790e-15  9.964609e-16   \n",
       "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
       "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
       "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
       "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
       "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
       "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.495077e-15 -6.116418e-16  1.279507e-16 -2.435559e-15  2.229535e-15   \n",
       "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
       "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
       "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
       "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
       "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
       "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  6.458078e-16  1.524623e-16 -3.402380e-16  2.593103e-16   \n",
       "std    ...  7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01   \n",
       "min    ... -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01   \n",
       "25%    ... -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01   \n",
       "50%    ... -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02   \n",
       "75%    ...  1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01   \n",
       "max    ...  3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.468456e-15  5.280639e-16  1.669484e-15 -3.610374e-16 -1.212174e-16   \n",
       "std    6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%    4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount  \n",
       "count  284807.000000  \n",
       "mean        0.003439  \n",
       "std         0.009736  \n",
       "min         0.000000  \n",
       "25%         0.000218  \n",
       "50%         0.000856  \n",
       "75%         0.003004  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_shuffled.copy()\n",
    "x[\"Amount\"] = x[\"Amount\"]/x.Amount.max()\n",
    "\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpZy-7csgU4P"
   },
   "source": [
    "### 5.3 Criar objeto Dataset\n",
    "\n",
    "Tendo os dados de entrada e de saída em um DataFrame Pandas, usamos o método `from_tensor_slices` para criar o Dataset. \n",
    "\n",
    "Para poder usar os dados do Dataframe, devemos tirar os nomes das colunas e passar somente os valores numéricos dos dados. Isso é feito usando a propriedade `values`, da forma apresentada na célula a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "83ERXcwigU4P"
   },
   "outputs": [],
   "source": [
    "# Define tamanho do lote\n",
    "batch_size = 1024\n",
    "\n",
    "# Cria Dataset\n",
    "creditcard_ds = tf.data.Dataset.from_tensor_slices((x.values, y.values)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoeEYxW1gU4P"
   },
   "source": [
    "- Observe que os valores numéricos do Dataframe são passados para o Dataset usando `x.values` e `y.values`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAvPUCq5gU4Q"
   },
   "source": [
    "Vamos gerar um elemento do Dataset para verificar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPvbTwG_gU4Q",
    "outputId": "e616e3a3-60e4-4eb3-c5bd-7c29f3d244ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1024, 29), dtype=float64, numpy=\n",
      "array([[-4.2639e+00,  1.5315e+00, -8.8185e-01, ..., -1.0955e+00,\n",
      "        -8.7706e-01,  1.0471e-04],\n",
      "       [ 1.9692e+00,  6.7800e-01, -1.0145e+00, ..., -4.7759e-02,\n",
      "        -4.5136e-02,  2.9310e-04],\n",
      "       [-1.3692e+00,  1.4338e+00,  1.2512e+00, ...,  5.4112e-01,\n",
      "         1.4969e-01,  3.4954e-04],\n",
      "       ...,\n",
      "       [-4.2397e+00,  2.7200e+00,  8.0646e-02, ..., -3.9757e+00,\n",
      "        -1.7962e+00,  5.4182e-04],\n",
      "       [-6.9893e-01,  1.0205e+00, -1.7921e-01, ..., -2.2792e-01,\n",
      "         1.9903e-01,  1.9423e-04],\n",
      "       [-5.6410e+00,  5.1650e+00, -1.4642e+00, ...,  2.1088e+00,\n",
      "         1.1237e+00,  3.4876e-04]])>, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for element in creditcard_ds.take(1):\n",
    "    print(format(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx9qmBRogU4Q"
   },
   "source": [
    "#### Divisão dos dados nos conjuntos de treinamento e teste\n",
    "\n",
    "Vamos dividir os dados nos conjuntos de treinamento e teste, de forma a ter 80% dos dados no conjunto de treinamento e 20% no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "GXd4ryMlgU4Q"
   },
   "outputs": [],
   "source": [
    "# Define função que seleciona exemplos de teste\n",
    "def is_test(x, y):\n",
    "    return x % 5 == 0\n",
    "\n",
    "# Define função que seleciiona exemplos de treinamento\n",
    "def is_train(x, y):\n",
    "    return not is_test(x, y)\n",
    "\n",
    "# Define função que elimina índice usado para selecionar exemplos incluidos com o método enumerate\n",
    "recover = lambda x,y: y\n",
    "\n",
    "# Cria Dataset de teste\n",
    "test_ds = creditcard_ds.enumerate().filter(is_test).map(recover)\n",
    "\n",
    "# Cria Dataset de treinamento\n",
    "train_ds = creditcard_ds.enumerate().filter(is_train).map(recover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TmrQtymgU4Q"
   },
   "source": [
    "Vamos gerar um exemplo de treinamento e um de teste para verificar se os Datasets estão corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89J8nLOrgU4Q",
    "outputId": "8a62900e-214b-497d-861c-b95e10862973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de treinamento:\\m (<tf.Tensor: shape=(1024, 29), dtype=float64, numpy=\n",
      "array([[-2.4543e-01,  1.3559e+00, -8.1479e-01, ..., -7.6784e-01,\n",
      "        -2.5735e-01,  1.1677e-04],\n",
      "       [ 4.4691e-01, -7.3020e-01,  3.1706e-01, ...,  5.5528e-02,\n",
      "        -8.1472e-03,  6.4614e-04],\n",
      "       [ 2.1377e+00, -8.0085e-01, -1.3817e+00, ...,  1.3391e-02,\n",
      "        -6.8732e-03,  1.3619e-03],\n",
      "       ...,\n",
      "       [-7.3781e-01,  2.0804e-01,  1.1668e+00, ..., -9.5773e-02,\n",
      "         4.1535e-02,  3.0353e-03],\n",
      "       [-7.1756e-02,  3.8175e-01,  1.2229e+00, ...,  1.9076e-01,\n",
      "         1.7579e-01,  5.8386e-04],\n",
      "       [-1.7032e+00,  2.5884e-01,  1.8866e-01, ..., -2.1116e-01,\n",
      "        -3.6240e-01,  7.0063e-04]])>, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int64)>)\n",
      " \n",
      "Exemplo de teste:\n",
      " (<tf.Tensor: shape=(1024, 29), dtype=float64, numpy=\n",
      "array([[-4.2639e+00,  1.5315e+00, -8.8185e-01, ..., -1.0955e+00,\n",
      "        -8.7706e-01,  1.0471e-04],\n",
      "       [ 1.9692e+00,  6.7800e-01, -1.0145e+00, ..., -4.7759e-02,\n",
      "        -4.5136e-02,  2.9310e-04],\n",
      "       [-1.3692e+00,  1.4338e+00,  1.2512e+00, ...,  5.4112e-01,\n",
      "         1.4969e-01,  3.4954e-04],\n",
      "       ...,\n",
      "       [-4.2397e+00,  2.7200e+00,  8.0646e-02, ..., -3.9757e+00,\n",
      "        -1.7962e+00,  5.4182e-04],\n",
      "       [-6.9893e-01,  1.0205e+00, -1.7921e-01, ..., -2.2792e-01,\n",
      "         1.9903e-01,  1.9423e-04],\n",
      "       [-5.6410e+00,  5.1650e+00, -1.4642e+00, ...,  2.1088e+00,\n",
      "         1.1237e+00,  3.4876e-04]])>, <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "# Verifica Dataset de treinamento \n",
    "for element in train_ds.take(1):\n",
    "    print('Exemplo de treinamento:\\m', format(element))\n",
    "\n",
    "print(' ')\n",
    "\n",
    "# Verifica Dataset de teste \n",
    "for element in test_ds.take(1):\n",
    "    print('Exemplo de teste:\\n', format(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov14SRrQyQE3"
   },
   "source": [
    "#### Criar Dataset que gera lotes com número de classes balanceadas\n",
    "\n",
    "Para criar lotes com número de exemplos balanceados entre as duas classes vamos utilizar a abordagem de amostragem do Dataset. Assim, primeiramente vamos criar os dois Datasets, uma para cada classe, para depois criar o Dataset que gera lotes balanceados.\n",
    "\n",
    "O ideal é fazer esse balanceamento para os conjuntos de treinamento e teste se formos usar os dados de teste para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "6YKfCPa-nioA"
   },
   "outputs": [],
   "source": [
    "# Cria Datasets com os dados sem fraude (negativo, classe = 0)\n",
    "negativos_ds_train = train_ds.unbatch().filter(lambda features, label: label==0).repeat()\n",
    "negativos_ds_test = test_ds.unbatch().filter(lambda features, label: label==0).repeat()\n",
    "\n",
    "# Cria Datasets com os dados com fraude (positivo, classe = 1)\n",
    "positivos_ds_train = train_ds.unbatch().filter(lambda features, label: label==1).repeat()\n",
    "positivos_ds_test = test_ds.unbatch().filter(lambda features, label: label==1).repeat()\n",
    "\n",
    "# Cria Datasets que gera lotes de elementos com as classes balanceadas\n",
    "balanced_ds_train = tf.data.experimental.sample_from_datasets(\n",
    "                    [negativos_ds_train, positivos_ds_train], [0.5, 0.5]).batch(batch_size)\n",
    "\n",
    "balanced_ds_test = tf.data.experimental.sample_from_datasets(\n",
    "                    [negativos_ds_test, positivos_ds_test], [0.5, 0.5]).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxjw1vq0gU4R"
   },
   "source": [
    "Geração de um lote para verificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oJL7r0RgU4R",
    "outputId": "c2f7134a-9e5b-4c04-f82f-777899a527fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 3.1460e-01  2.6607e+00 -5.9200e+00 ...  6.2087e-01  1.8503e-01\n",
      "   3.8924e-05]\n",
      " [-1.0301e+01  6.4831e+00 -1.5076e+01 ... -4.6889e-01  1.0592e-01\n",
      "   3.8924e-05]\n",
      " [-8.4268e+00  6.2417e+00 -9.9465e+00 ...  1.1957e+00  1.9829e-01\n",
      "   3.4343e-03]\n",
      " ...\n",
      " [ 1.3164e+00  6.0456e-02 -1.2039e+00 ... -6.7411e-02 -2.4594e-03\n",
      "   4.5619e-04]\n",
      " [ 1.1708e+00  2.5010e+00 -4.9862e+00 ...  4.8159e-01  2.6823e-01\n",
      "   1.9345e-04]\n",
      " [-2.8800e+00  5.2254e+00 -1.1063e+01 ...  1.4277e+00  5.8317e-01\n",
      "   3.8924e-05]], shape=(1024, 29), dtype=float64)\n",
      "tf.Tensor([1 1 1 ... 0 1 1], shape=(1024,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in balanced_ds_train.take(1):\n",
    "    print(features)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-ZI6SdpgU4R"
   },
   "source": [
    "Vamos verificar o resultado dessas operações verificando o número de exemplos de cada classe de um lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Myvkw21Rz-fH",
    "outputId": "28110a54-ea99-4aa5-ad7b-be9fe6839dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de exemplo com fraude (classe=1): 524\n",
      "Número de exemplo sem fraude (classe=0): 500\n",
      " \n",
      "Número de exemplo com fraude (classe=1): 481\n",
      "Número de exemplo sem fraude (classe=0): 543\n",
      " \n",
      "Número de exemplo com fraude (classe=1): 527\n",
      "Número de exemplo sem fraude (classe=0): 497\n",
      " \n",
      "Número de exemplo com fraude (classe=1): 488\n",
      "Número de exemplo sem fraude (classe=0): 536\n",
      " \n",
      "Número de exemplo com fraude (classe=1): 498\n",
      "Número de exemplo sem fraude (classe=0): 526\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gera 1 lote do Dataset balanced_ds\n",
    "for features, labels in balanced_ds_train.take(5):\n",
    "    n1 = tf.reduce_sum(labels)\n",
    "    print('Número de exemplo com fraude (classe=1):', n1.numpy())\n",
    "    print('Número de exemplo sem fraude (classe=0):', (batch_size - n1).numpy())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh0hbKtEgU4R"
   },
   "source": [
    "-  Pode-se ver que o número de exemplos de cada classe é quase o mesmo em todos os lotes gerados, girando em torno de 512, que é metade do tamanho do lote de 1024 exemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8_JRTB_gU4R"
   },
   "source": [
    "### 5.4 Configuração e compilação da RNA\n",
    "\n",
    "Para resolver esse problema vamos utilizar uma RNA com duas camadas densas, com a configuração a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9kJU6KngU4S",
    "outputId": "efa89437-ce9f-4aff-d821-5836ba66a976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importa classes\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Configura RNA\n",
    "rna = Sequential()\n",
    "rna.add(Dense(128, activation='relu', input_shape=(29,)))\n",
    "rna.add(Dense(64, activation='relu'))\n",
    "rna.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Apresenta sumário da RNA\n",
    "rna.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5_uTT9SCOq6"
   },
   "source": [
    "Para compilar a RNA usaremos os seguintes parâmetros:\n",
    "\n",
    "- Método de otimização: Adam\n",
    "- Taxa de aprendizado: 0.001\n",
    "- Métrica: exatidão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kBo1iCMOgU4S"
   },
   "outputs": [],
   "source": [
    "# Compila RNA\n",
    "rna.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvr5QddOgU4S"
   },
   "source": [
    "### 5.5 Treinamento da RNA\n",
    " \n",
    "Para treinar a RNA basta passar os Datasets de treinamento e teste.  \n",
    "\n",
    "Somente para exemplificar, vamos usar poucas épocas de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EM_XQIzgU4S",
    "outputId": "9e9dcfd1-66d7-40ef-ca9b-75d41cf6283a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 233s 12s/step - loss: 0.0886 - accuracy: 0.9621 - val_loss: 0.1595 - val_accuracy: 0.9482\n"
     ]
    }
   ],
   "source": [
    "results = rna.fit(balanced_ds_train.repeat(),\n",
    "                  steps_per_epoch=20,\n",
    "                  epochs=10,\n",
    "                  validation_data=balanced_ds_test.repeat(),\n",
    "                  validation_steps=1,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWvUCPUHgU4S"
   },
   "source": [
    "**Importante:**\n",
    "\n",
    "Usar um Dataset com o método `repeat` gera infinitos exemplos de treinamento. Nesse caso, no treinamento deve-se usar o argumento `steps_per_epoch` e `validation_steps` para definir quantos lotes por época são desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "fRGaQFSY3d8g",
    "outputId": "3d0b13a5-bde4-4923-8a86-e25addf5d808"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salva treinamento na variável history para visualização\n",
    "resultado = results.history\n",
    "\n",
    "# Salva custos, métricas e epocas em vetores \n",
    "custo = resultado['loss']\n",
    "acc = resultado['accuracy']\n",
    "val_custo = resultado['val_loss']\n",
    "val_acc = resultado['val_accuracy']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocas = range(1, len(custo) + 1)\n",
    "\n",
    "# Gráfico dos valores de custo\n",
    "plt.plot(epocas, custo, 'bo', label='Custo - treinamento')\n",
    "plt.plot(epocas, val_custo, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocas, acc, 'bo', label='exatidao- treinamento')\n",
    "plt.plot(epocas, val_acc, 'b', label='exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCtnEwu8gU4S"
   },
   "source": [
    "### 5.7 Avaliação e teste da RNA\n",
    "\n",
    "Vamos avaliar o desemepnho da RNA usando o método `evaluate`com os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDuvPruhgU4S",
    "outputId": "271675f8-a941-4ab9-bb01-9340215638f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/10 [==>...........................] - ETA: 1:48 - loss: 0.1619 - accuracy: 0.9482"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9b1e28c98822>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calcula função de custo e exatidão para os dados de teste\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbalanced_ds_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Função de custo:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calcula função de custo e exatidão para os dados de teste \n",
    "loss, accuracy = rna.evaluate(balanced_ds_test, steps=10)\n",
    "\n",
    "print(' ')\n",
    "print(\"Função de custo:\", loss)\n",
    "print(\"Exatidão:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waRgvMCjgU4T"
   },
   "source": [
    "#### Realizar previsões\n",
    "\n",
    "Vamos verificar os resultados da RNA com detalhe usando o método predict e depois verificar o acerto para cada uma das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "u_EUqslagU4T"
   },
   "outputs": [],
   "source": [
    "# Gera lote de dados \n",
    "x, y_real = next(iter(balanced_ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-HDw4y5G41j0",
    "outputId": "7bacc2a8-3397-42b8-f12d-6846bb1fb404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão = 0.9501953125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcula previsão da RNA para um lote de imagens\n",
    "y_prev = rna.predict(x)\n",
    "classe_prev = np.round(y_prev)\n",
    "\n",
    "# Redimensiona vetor de classes reais\n",
    "classe_real = np.reshape(y_real, (1024, 1))\n",
    "\n",
    "# Exatidão obtida\n",
    "print('Exatidão =', 1.0 - np.mean(np.abs(classe_real-classe_prev)))\n",
    "\n",
    "# Mostra primeiro exemplo do lote\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(y_real[:250], 'bo')\n",
    "plt.plot(classe_prev[:250], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHdVHbG36WTi"
   },
   "outputs": [],
   "source": [
    "rna.save('rna.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A5_Data_pipeline_Parte2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
